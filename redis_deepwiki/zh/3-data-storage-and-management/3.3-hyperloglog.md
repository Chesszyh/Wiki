# HyperLogLog

相关源文件

-   [src/commands/pfmerge.json](https://github.com/redis/redis/blob/8ad54215/src/commands/pfmerge.json)
-   [src/hyperloglog.c](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c)
-   [tests/unit/hyperloglog.tcl](https://github.com/redis/redis/blob/8ad54215/tests/unit/hyperloglog.tcl)
-   [utils/generate-module-api-doc.rb](https://github.com/redis/redis/blob/8ad54215/utils/generate-module-api-doc.rb)

本文涵盖了 Redis 的 HyperLogLog 实现，这是一种用于基数估计 (cardinality estimation) 的概率数据结构。HyperLogLog 允许在大数据集中高效估计唯一元素的数量，且无论实际基数大小如何，仅占用固定内存 (12KB)。Redis 使用两种表示形式：低基数时使用更节省内存的稀疏表示 (sparse)，高基数时使用稠密表示 (dense)。

有关其他概率数据结构的信息，请参阅 [核心数据类型实现](/redis/redis/3.1-core-data-types-implementation) 中的主要数据类型实现。

## 算法概览

Redis 实现了 HyperLogLog 算法，使用 64 位哈希函数和 16,384 个 6 位寄存器，为数十亿个唯一元素的基数估计提供高精度。

```mermaid
flowchart TD
    INPUT["输入元素"]
    HASH["MurmurHash64A()"]
    EXTRACT["提取寄存器索引 (14 位)"]
    COUNT["统计前导零数量 + 1"]
    REG["寄存器数组 [16384]"]
    UPDATE["如果计数 > 当前值则更新寄存器"]
    ESTIMATE["调和平均数估计"]
    CARDINALITY["估计基数"]
    CHECK["计数 > 当前值？"]
    SET["设置新值"]
    SKIP["跳过更新"]

    INPUT --> HASH
    HASH --> EXTRACT
    HASH --> COUNT
    EXTRACT --> REG
    COUNT --> UPDATE
    UPDATE --> REG
    REG --> ESTIMATE
    ESTIMATE --> CARDINALITY
    UPDATE --> CHECK
    CHECK --> SET
    CHECK --> SKIP
```

**HyperLogLog 算法流程**

该算法使用 `MurmurHash64A` 哈希函数处理元素，从前 14 位提取寄存器索引，并统计剩余 50 位中的前导零数量。每个寄存器存储哈希到该寄存器的元素所见过的最大前导零计数。

**来源：** [src/hyperloglog.c29-47](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L29-L47) [src/hyperloglog.c451-472](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L451-L472) [src/hyperloglog.c1042-1077](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L1042-L1077)

## 数据结构与表示

### HLL 头部结构

```mermaid
flowchart TD
    MAGIC["幻数：'HYLL' (4 字节)"]
    ENC["编码 (1 字节)"]
    UNUSED["未使用的字节 (3 字节)"]
    CARD["缓存的基数 (8 字节, 小端序)"]
    DENSE["HLL_DENSE (0) 6 位寄存器"]
    SPARSE["HLL_SPARSE (1) 运行长度压缩"]
    DATA["寄存器数据 (可变长度)"]

    ENC --> DENSE
    ENC --> SPARSE
    HEADER --> DATA
```

**HLL 数据结构布局**

`struct hllhdr` 定义了两种表示形式通用的头部格式。缓存的基数使用最高有效位 (MSB) 作为失效标志。

**来源：** [src/hyperloglog.c57-79](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L57-L79) [src/hyperloglog.c174-180](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L174-L180) [src/hyperloglog.c182-184](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L182-L184)

### 稠密 vs 稀疏表示

```mermaid
flowchart TD
    ZERO["ZERO：00xxxxxx (1-64 个零寄存器)"]
    XZERO["XZERO：01xxxxxx yyyyyyyy (1-16384 个零寄存器)"]
    VAL["VAL：1vvvvvxx (1-4 个值为 1-32 的寄存器)"]
    SPARSE_HDR["16 字节头部"]
    SPARSE_OPS["可变操作码"]
    SPARSE_DESC["可变内存 运行长度编码"]
    DENSE_HDR["16 字节头部"]
    DENSE_REG["12,288 字节 (16384 × 6 位)"]
    DENSE_DESC["固定 12KB 内存 所有寄存器均存在"]
    PROMOTE["当稀疏大小 > hll_sparse_max_bytes 时自动晋升"]

    SPARSE --> PROMOTE
    PROMOTE --> DENSE
    SPARSE --> HDR_SPARSE_OPS
    SPARSE --> OPS_OPCODES
    DENSE --> HDR_DENSE_REG
```

**稠密与稀疏表示对比**

当稀疏表示超过 `server.hll_sparse_max_bytes` 或寄存器值超过 32 时，Redis 会自动将其从稀疏表示晋升为稠密表示。

**来源：** [src/hyperloglog.c48-172](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L48-L172) [src/hyperloglog.c577-642](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L577-L642) [src/hyperloglog.c659-911](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L659-L911)

## 核心操作

### 元素添加过程

```mermaid
flowchart TD
    ELEMENT["元素数据"]
    HLLPATLEN["hllPatLen()"]
    HASH["MurmurHash64A()"]
    INDEX["提取索引 (14 位)"]
    ZEROS["统计前导零数量"]
    ENCODING["检查编码"]
    DENSE_ADD["hllDenseAdd()"]
    SPARSE_ADD["hllSparseAdd()"]
    DENSE_SET["hllDenseSet()"]
    SPARSE_SET["hllSparseSet()"]
    CHECK_PROMOTE["值 > 32 或大小 > max_bytes？"]
    PROMOTE["hllSparseToDense() 稀疏转稠密"]
    SPARSE_UPDATE["更新稀疏数据"]
    INVALIDATE["失效缓存"]
    RETURN["返回修改标志"]

    ELEMENT --> HLLPATLEN
    HLLPATLEN --> HASH
    HASH --> INDEX
    HASH --> ZEROS
    INDEX --> ENCODING
    ZEROS --> ENCODING
    ENCODING --> DENSE_ADD
    ENCODING --> SPARSE_ADD
    DENSE --> ADD_DENSE_SET
    SPARSE --> ADD_SPARSE_SET
    SPARSE --> SET_CHECK_PROMOTE
    CHECK --> PROMOTE_PROMOTE
    CHECK --> PROMOTE_SPARSE_UPDATE
    PROMOTE --> DENSE_SET
    DENSE --> SET_INVALIDATE
    SPARSE --> UPDATE_INVALIDATE
    INVALIDATE --> RETURN
```

**元素添加流程**

`hllAdd` 函数根据当前编码路由到稠密或稀疏实现，并在必要时自动执行晋升。

**来源：** [src/hyperloglog.c1079-1087](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L1079-L1087) [src/hyperloglog.c486-509](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L486-L509) [src/hyperloglog.c913-924](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L913-L924)

### 基数估计

```mermaid
flowchart TD
    HLL_COUNT["hllCount()"]
    GET_HISTO["构建寄存器直方图"]
    DENSE_HISTO["hllDenseRegHisto()"]
    SPARSE_HISTO["hllSparseRegHisto()"]
    RAW_HISTO["hllRawRegHisto()"]
    CALC["基数计算"]
    TAU["hllTau() 函数"]
    SIGMA["hllSigma() 函数"]
    FORMULA["E = α∞ × m² / z"]
    RESULT["返回估计计数"]

    HLL --> COUNT_GET_HISTO
    GET --> HISTO_DENSE_HISTO
    GET --> HISTO_SPARSE_HISTO
    GET --> HISTO_RAW_HISTO
    DENSE --> HISTO_CALC
    SPARSE --> HISTO_CALC
    RAW --> HISTO_CALC
    CALC --> TAU
    CALC --> SIGMA
    TAU --> FORMULA
    SIGMA --> FORMULA
    FORMULA --> RESULT
```

**基数估计过程**

该估计使用了一种改进的算法，基于 Otmar Ertl 的论文《New cardinality estimation algorithms for HyperLogLog sketches》，并使用了 tau 和 sigma 修正函数。

**来源：** [src/hyperloglog.c1042-1077](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L1042-L1077) [src/hyperloglog.c997-1029](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L997-L1029) [src/hyperloglog.c512-567](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L512-L567)

## 命令与 API

### Redis HyperLogLog 命令

| 命令 | 函数 | 用途 |
| --- | --- | --- |
| `PFADD` | `pfaddCommand` | 向 HyperLogLog 添加元素 |
| `PFCOUNT` | `pfcountCommand` | 获取基数估计值 |
| `PFMERGE` | `pfmergeCommand` | 合并多个 HyperLogLog |
| `PFDEBUG` | `pfdebugCommand` | 调试操作 |

```mermaid
flowchart TD
    CLIENT["Redis 客户端"]
    CMD_PARSE["命令解析器"]
    PFADD["PFADD key elements..."]
    PFCOUNT["PFCOUNT key [key ...]"]
    PFMERGE["PFMERGE destkey sourcekey [sourcekey ...]"]
    ADD_VALIDATE["验证 HLL 对象"]
    ADD_ELEMENTS["添加每个元素"]
    HLL_ADD["hllAdd()"]
    COUNT_VALIDATE["验证 HLL 对象"]
    MULTI_COUNT["是否为多个键？"]
    MERGE_TEMP["合并到临时对象"]
    SINGLE_COUNT["hllCount()"]
    MERGE_VALIDATE["验证对象"]
    HLL_MERGE["hllMerge()"]
    REPLY["回复客户端"]

    CLIENT --> CMD_PARSE
    CMD --> PARSE_PFADD
    CMD --> PARSE_PFCOUNT
    CMD --> PARSE_PFMERGE
    PFADD --> ADD_VALIDATE
    ADD --> VALIDATE_ADD_ELEMENTS
    ADD --> ELEMENTS_HLL_ADD
    PFCOUNT --> COUNT_VALIDATE
    COUNT --> VALIDATE_MULTI_COUNT
    MULTI --> COUNT_MERGE_TEMP
    MULTI --> COUNT_SINGLE_COUNT
    MERGE --> TEMP_SINGLE_COUNT
    PFMERGE --> MERGE_VALIDATE
    MERGE --> VALIDATE_HLL_MERGE
    HLL --> ADD_REPLY
    SINGLE --> COUNT_REPLY
    HLL --> MERGE_REPLY
```

**命令处理流程**

在执行操作前，命令使用 `isHLLObjectOrReply()` 验证 HLL 对象。多键 `PFCOUNT` 会创建一个临时的合并表示形式用于估计。

**来源：** [src/hyperloglog.c1461-1525](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L1461-L1525) [src/hyperloglog.c1527-1622](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L1527-L1622) [src/hyperloglog.c1624-1720](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L1624-L1720)

## 内存管理与优化

### AVX2 SIMD 优化

```mermaid
flowchart TD
    MERGE_REQ["合并请求"]
    CHECK_AVX2["AVX2 支持且为默认配置？"]
    AVX2_MERGE["hllMergeDenseAVX2()"]
    SCALAR_MERGE["标准的 hllMergeDense()"]
    LOAD_32["每次迭代加载 32 个寄存器"]
    SHUFFLE["使用 _mm256_shuffle_epi8 打乱位"]
    EXTRACT["通过 AND/SHIFT 提取 6 位值"]
    MAX_OP["向量化 MAX 操作"]
    STORE["存储结果"]
    LOOP["逐个寄存器循环"]
    RESULT["合并后的 HLL"]

    MERGE --> REQ_CHECK_AVX2
    CHECK --> AVX2_AVX2_MERGE
    CHECK --> AVX2_SCALAR_MERGE
    AVX2 --> MERGE_LOAD_32
    LOAD --> 32_SHUFFLE
    SHUFFLE --> EXTRACT
    EXTRACT --> MAX_OP
    MAX --> OP_STORE
    SCALAR --> MERGE_LOOP
    STORE --> RESULT
    LOOP --> RESULT
```

**针对稠密合并的 AVX2 SIMD 优化**

该实现包含经过 AVX2 优化的稠密合并，每次迭代处理 32 个寄存器，显著提高了对稠密 HyperLogLog 执行 `PFMERGE` 操作的性能。

**来源：** [src/hyperloglog.c1089-1193](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L1089-L1193) [src/hyperloglog.c1195-1213](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L1195-L1213)

### 稀疏表示管理

```mermaid
flowchart TD
    SPARSE_SET["hllSparseSet()"]
    CHECK_SIZE["检查可用空间"]
    RESIZE["需要调整大小？"]
    GREEDY["贪婪分配 min(2×当前大小, 300 额外字节)"]
    CONTINUE["继续操作"]
    MAX_CHECK["大小 > max_bytes？"]
    PROMOTE["晋升为稠密表示"]
    ALLOCATE["sdsResize()"]
    LOCATE["定位目标操作码"]
    SPLIT["如果需要则拆分操作码"]
    MERGE_OPT["合并相邻值"]
    INVALIDATE["失效缓存"]
    DENSE_OP["稠密操作"]

    SPARSE --> SET_CHECK_SIZE
    CHECK --> SIZE_RESIZE
    RESIZE --> GREEDY
    RESIZE --> CONTINUE
    GREEDY --> MAX_CHECK
    MAX --> CHECK_PROMOTE
    MAX --> CHECK_ALLOCATE
    ALLOCATE --> LOCATE
    CONTINUE --> LOCATE
    LOCATE --> SPLIT
    SPLIT --> MERGE_OPT
    MERGE --> OPT_INVALIDATE
    PROMOTE --> DENSE_OP
    DENSE --> OP_INVALIDATE
```

**稀疏表示内存管理**

稀疏实现使用贪婪分配来最小化重新分配次数，并包含操作码合并优化以保持紧凑表示。

**来源：** [src/hyperloglog.c678-684](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L678-L684) [src/hyperloglog.c792-852](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L792-L852) [src/hyperloglog.c855-891](https://github.com/redis/redis/blob/8ad54215/src/hyperloglog.c#L855-L891)
