# Backend Implementations

Relevant source files

-   [celery/app/builtins.py](https://github.com/celery/celery/blob/4d068b56/celery/app/builtins.py)
-   [celery/backends/\_\_init\_\_.py](https://github.com/celery/celery/blob/4d068b56/celery/backends/__init__.py)
-   [celery/backends/base.py](https://github.com/celery/celery/blob/4d068b56/celery/backends/base.py)
-   [celery/backends/cache.py](https://github.com/celery/celery/blob/4d068b56/celery/backends/cache.py)
-   [celery/backends/redis.py](https://github.com/celery/celery/blob/4d068b56/celery/backends/redis.py)
-   [celery/backends/rpc.py](https://github.com/celery/celery/blob/4d068b56/celery/backends/rpc.py)
-   [celery/result.py](https://github.com/celery/celery/blob/4d068b56/celery/result.py)
-   [docs/userguide/configuration.rst](https://github.com/celery/celery/blob/4d068b56/docs/userguide/configuration.rst)
-   [t/unit/backends/test\_base.py](https://github.com/celery/celery/blob/4d068b56/t/unit/backends/test_base.py)
-   [t/unit/backends/test\_redis.py](https://github.com/celery/celery/blob/4d068b56/t/unit/backends/test_redis.py)
-   [t/unit/tasks/test\_chord.py](https://github.com/celery/celery/blob/4d068b56/t/unit/tasks/test_chord.py)
-   [t/unit/tasks/test\_result.py](https://github.com/celery/celery/blob/4d068b56/t/unit/tasks/test_result.py)

This document covers the specific implementations of result backends in Celery. These implementations provide the concrete functionality for storing, retrieving, and managing task results using different storage systems. For the overall backend architecture and interfaces, see [Result Backend Architecture](/celery/celery/5.1-worker-architecture-and-bootsteps). For working with results from a user perspective, see [Working with Results](/celery/celery/5.3-concurrency-models).

## Backend Implementation Overview

Celery provides multiple backend implementations that extend the base backend architecture to support different storage systems. Each implementation provides specific capabilities and trade-offs for result storage and retrieval.

### Backend Implementation Architecture

```mermaid
flowchart TD
    BaseBackend["BaseBackendbase.py"]
    KeyValueBackend["BaseKeyValueStoreBackendbase.py"]
    AsyncMixin["AsyncBackendMixinasynchronous.py"]
    RedisBackend["RedisBackendredis.py"]
    ElasticsearchBackend["ElasticsearchBackendelasticsearch.py"]
    MongoBackend["MongoBackendmongodb.py"]
    CassandraBackend["CassandraBackendcassandra.py"]
    RedisClient["redis.StrictRedis"]
    ESClient["elasticsearch.Elasticsearch"]
    MongoClient["pymongo.MongoClient"]
    CassandraCluster["cassandra.cluster.Cluster"]

    BaseBackend --> KeyValueBackend
    BaseBackend --> MongoBackend
    BaseBackend --> CassandraBackend
    KeyValueBackend --> RedisBackend
    KeyValueBackend --> ElasticsearchBackend
    AsyncMixin --> RedisBackend
    RedisBackend --> RedisClient
    ElasticsearchBackend --> ESClient
    MongoBackend --> MongoClient
    CassandraBackend --> CassandraCluster
```
### Backend Feature Matrix

| Backend | Base Class | Async Support | Chord Support | Auto Expire | Native Join |
| --- | --- | --- | --- | --- | --- |
| `RedisBackend` | `BaseKeyValueStoreBackend` | ✅ | ✅ | ✅ | ✅ |
| `MongoBackend` | `BaseBackend` | ❌ | ❌ | ❌ | ❌ |
| `CassandraBackend` | `BaseBackend` | ❌ | ❌ | ✅ | ❌ |
| `ElasticsearchBackend` | `KeyValueStoreBackend` | ❌ | ❌ | ❌ | ❌ |

Sources: [celery/backends/mongodb.py54](https://github.com/celery/celery/blob/4d068b56/celery/backends/mongodb.py#L54-L54) [celery/backends/cassandra.py86](https://github.com/celery/celery/blob/4d068b56/celery/backends/cassandra.py#L86-L86) [celery/backends/elasticsearch.py30](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L30-L30)

## Redis Backend Implementation

The `RedisBackend` is the most feature-complete backend implementation, providing high-performance result storage with full async support and chord coordination. It extends `BaseKeyValueStoreBackend` and `AsyncBackendMixin`.

### Redis Backend Architecture

```mermaid
flowchart TD
    RedisBackend["RedisBackendredis.py:188"]
    ResultConsumer["ResultConsumerredis.py:81"]
    BaseKVStore["BaseKeyValueStoreBackend"]
    AsyncMixin["AsyncBackendMixin"]
    BasicOps["Basic OperationsGET, SET, MGET, DEL"]
    ChordOps["Chord OperationsZADD, ZRANGE, INCR"]
    PubSubOps["Pub/Sub OperationsPUBLISH, SUBSCRIBE"]
    PipelineOps["Pipeline OperationsBatch commands"]
    ConnPool["ConnectionPoolredis.ConnectionPool"]
    RetryPolicy["Retry Policyretry_over_time()"]
    ConnErrors["Connection Errorsget_redis_error_classes()"]
    PubSub["PubSubredis.pubsub()"]
    EventDrain["drain_events()Message processing"]
    StateChange["on_state_change()Result delivery"]

    RedisBackend --> BaseKVStore
    RedisBackend --> AsyncMixin
    RedisBackend --> ResultConsumer
    RedisBackend --> BasicOps
    RedisBackend --> ChordOps
    RedisBackend --> PubSubOps
    RedisBackend --> PipelineOps
    RedisBackend --> ConnPool
    RedisBackend --> RetryPolicy
    RedisBackend --> ConnErrors
    ResultConsumer --> PubSub
    ResultConsumer --> EventDrain
    ResultConsumer --> StateChange
```
### Redis Backend Features

The `RedisBackend` class [celery/backends/redis.py188-615](https://github.com/celery/celery/blob/4d068b56/celery/backends/redis.py#L188-L615) provides comprehensive result backend capabilities:

**Feature Support:**

-   `supports_autoexpire = True` - TTL-based expiration [celery/backends/redis.py204](https://github.com/celery/celery/blob/4d068b56/celery/backends/redis.py#L204-L204)
-   `supports_native_join = True` - Native result joining [celery/backends/redis.py205](https://github.com/celery/celery/blob/4d068b56/celery/backends/redis.py#L205-L205)
-   `implements_incr = True` - Atomic increment operations via `incr()` [celery/backends/redis.py424-425](https://github.com/celery/celery/blob/4d068b56/celery/backends/redis.py#L424-L425)

**Core Operations:**

-   `get(key)` - Single key retrieval [celery/backends/redis.py381-382](https://github.com/celery/celery/blob/4d068b56/celery/backends/redis.py#L381-L382)
-   `mget(keys)` - Bulk key retrieval [celery/backends/redis.py384-385](https://github.com/celery/celery/blob/4d068b56/celery/backends/redis.py#L384-L385)
-   `set(key, value)` - Store with pipeline publish [celery/backends/redis.py402-415](https://github.com/celery/celery/blob/4d068b56/celery/backends/redis.py#L402-L415)
-   `delete(key)` - Key deletion [celery/backends/redis.py421-422](https://github.com/celery/celery/blob/4d068b56/celery/backends/redis.py#L421-L422)

**Chord Coordination:** The Redis backend implements sophisticated chord coordination through `on_chord_part_return()` [celery/backends/redis.py469-556](https://github.com/celery/celery/blob/4d068b56/celery/backends/redis.py#L469-L556) using Redis sorted sets (`ZADD`/`ZRANGE`) or lists (`RPUSH`/`LRANGE`) for ordered result collection.

### Redis Connection Configuration

The backend supports extensive Redis connection configuration [celery/backends/redis.py234-273](https://github.com/celery/celery/blob/4d068b56/celery/backends/redis.py#L234-L273):

| Parameter | Configuration Key | Description |
| --- | --- | --- |
| `host` | `redis_host` | Redis server hostname |
| `port` | `redis_port` | Redis server port |
| `db` | `redis_db` | Redis database number |
| `password` | `redis_password` | Authentication password |
| `username` | `redis_username` | Username (Redis 6.0+) |
| `max_connections` | `redis_max_connections` | Connection pool size |

Sources: [celery/backends/redis.py188-615](https://github.com/celery/celery/blob/4d068b56/celery/backends/redis.py#L188-L615) [celery/backends/redis.py81-186](https://github.com/celery/celery/blob/4d068b56/celery/backends/redis.py#L81-L186)

## MongoDB Backend Implementation

The `MongoBackend` provides result storage using MongoDB document database. It extends `BaseBackend` directly and handles document-based storage with BSON serialization support.

### MongoDB Backend Architecture

```mermaid
flowchart TD
    MongoBackend["MongoBackend"]
    BaseBackend["BaseBackend"]
    PymongoClient["pymongo.MongoClient"]
    PymongoURIParser["pymongo.uri_parser"]
    collection["collection property"]
    group_collection["group_collection property"]
    taskmeta_collection["taskmeta_collection"]
    groupmeta_collection["groupmeta_collection"]
    create_index["create_index('date_done')"]
    encode_method["encode()"]
    decode_method["decode()"]
    Binary["Binary() wrapper"]
    BINARY_CODECS["BINARY_CODECS frozenset"]
    _store_result["_store_result()"]
    _get_task_meta_for["_get_task_meta_for()"]
    _save_group["_save_group()"]
    _restore_group["_restore_group()"]
    replace_one["replace_one(upsert=True)"]
    find_one["find_one()"]

    MongoBackend --> BaseBackend
    MongoBackend --> PymongoClient
    MongoBackend --> PymongoURIParser
    MongoBackend --> collection
    MongoBackend --> group_collection
    collection --> taskmeta_collection
    group --> collection_groupmeta_collection
    collection --> create_index
    MongoBackend --> encode_method
    MongoBackend --> decode_method
    encode --> method_Binary
    encode --> method_BINARY_CODECS
    MongoBackend --> _store_result
    MongoBackend --> _get_task_meta_for
    MongoBackend --> _save_group
    MongoBackend --> _restore_group
    _store --> result_replace_one
    _get --> task_meta_for_find_one
```
### MongoDB Backend Operations

The `MongoBackend` class [celery/backends/mongodb.py35-334](https://github.com/celery/celery/blob/4d068b56/celery/backends/mongodb.py#L35-L334) implements document-based result storage:

**Core Operations:**

-   `_store_result()` - Store task result using `replace_one()` with upsert [celery/backends/mongodb.py181-194](https://github.com/celery/celery/blob/4d068b56/celery/backends/mongodb.py#L181-L194)
-   `_get_task_meta_for()` - Retrieve task metadata using `find_one()` [celery/backends/mongodb.py197-224](https://github.com/celery/celery/blob/4d068b56/celery/backends/mongodb.py#L197-L224)
-   `_save_group()` - Store group result [celery/backends/mongodb.py226-234](https://github.com/celery/celery/blob/4d068b56/celery/backends/mongodb.py#L226-L234)
-   `_restore_group()` - Retrieve group result [celery/backends/mongodb.py236-247](https://github.com/celery/celery/blob/4d068b56/celery/backends/mongodb.py#L236-L247)
-   `_delete_group()` - Delete group by ID [celery/backends/mongodb.py249-251](https://github.com/celery/celery/blob/4d068b56/celery/backends/mongodb.py#L249-L251)
-   `_forget()` - Remove result using `delete_one()` [celery/backends/mongodb.py253-263](https://github.com/celery/celery/blob/4d068b56/celery/backends/mongodb.py#L253-L263)
-   `cleanup()` - Delete expired documents [celery/backends/mongodb.py265-275](https://github.com/celery/celery/blob/4d068b56/celery/backends/mongodb.py#L265-L275)

**Document Structure:** Each task result is stored as a MongoDB document with `_id` as the task ID [celery/backends/mongodb.py188](https://github.com/celery/celery/blob/4d068b56/celery/backends/mongodb.py#L188-L188) and includes standard metadata fields like `status`, `result`, `date_done`, and `traceback`. Extended metadata includes `name`, `args`, `kwargs`, `queue`, `worker`, and `retries` [celery/backends/mongodb.py201-215](https://github.com/celery/celery/blob/4d068b56/celery/backends/mongodb.py#L201-L215)

**Binary Codec Handling:** The backend handles serialization through `BINARY_CODECS = frozenset(['pickle', 'msgpack'])` [celery/backends/mongodb.py32](https://github.com/celery/celery/blob/4d068b56/celery/backends/mongodb.py#L32-L32) and wraps binary data with `Binary()` for MongoDB storage [celery/backends/mongodb.py172-173](https://github.com/celery/celery/blob/4d068b56/celery/backends/mongodb.py#L172-L173)

**Connection Management:**

-   `_get_connection()` - Creates `MongoClient` with connection options [celery/backends/mongodb.py136-163](https://github.com/celery/celery/blob/4d068b56/celery/backends/mongodb.py#L136-L163)
-   `_ensure_mongodb_uri_compliance()` - Validates and normalizes MongoDB URIs [celery/backends/mongodb.py118-127](https://github.com/celery/celery/blob/4d068b56/celery/backends/mongodb.py#L118-L127)
-   `_prepare_client_options()` - Configures client options based on PyMongo version [celery/backends/mongodb.py129-134](https://github.com/celery/celery/blob/4d068b56/celery/backends/mongodb.py#L129-L134)

Sources: [celery/backends/mongodb.py32](https://github.com/celery/celery/blob/4d068b56/celery/backends/mongodb.py#L32-L32) [celery/backends/mongodb.py136-163](https://github.com/celery/celery/blob/4d068b56/celery/backends/mongodb.py#L136-L163) [celery/backends/mongodb.py181-275](https://github.com/celery/celery/blob/4d068b56/celery/backends/mongodb.py#L181-L275)

## Cassandra Backend Implementation

The `CassandraBackend` provides result storage using Apache Cassandra or AstraDB. It extends `BaseBackend` and supports both regular Cassandra clusters and cloud-based AstraDB with secure connect bundles.

### Cassandra Backend Architecture

```mermaid
flowchart TD
    CassandraBackend["CassandraBackend"]
    BaseBackend["BaseBackend"]
    cassandra_cluster_Cluster["cassandra.cluster.Cluster"]
    cassandra_query_SimpleStatement["cassandra.query.SimpleStatement"]
    servers["servers parameter"]
    bundle_path["bundle_path parameter"]
    auth_provider["auth_provider"]
    cassandra_options["cassandra_options"]
    _cluster["_cluster instance"]
    _session["_session instance"]
    Q_INSERT_RESULT["Q_INSERT_RESULT"]
    Q_SELECT_RESULT["Q_SELECT_RESULT"]
    Q_CREATE_RESULT_TABLE["Q_CREATE_RESULT_TABLE"]
    Q_EXPIRES["Q_EXPIRES (TTL)"]
    _write_stmt["_write_stmt"]
    _read_stmt["_read_stmt"]
    write_consistency["write_consistency"]
    read_consistency["read_consistency"]
    _get_connection["_get_connection()"]
    _store_result["_store_result()"]
    _get_task_meta_for["_get_task_meta_for()"]
    buf_t["buf_t() encoding"]

    CassandraBackend --> BaseBackend
    CassandraBackend --> cassandra_cluster_Cluster
    CassandraBackend --> cassandra_query_SimpleStatement
    CassandraBackend --> servers
    CassandraBackend --> bundle_path
    CassandraBackend --> auth_provider
    CassandraBackend --> cassandra_options
    CassandraBackend --> _cluster
    CassandraBackend --> _session
    CassandraBackend --> Q_INSERT_RESULT
    CassandraBackend --> Q_SELECT_RESULT
    CassandraBackend --> Q_CREATE_RESULT_TABLE
    CassandraBackend --> Q_EXPIRES
    CassandraBackend --> _write_stmt
    CassandraBackend --> _read_stmt
    CassandraBackend --> write_consistency
    CassandraBackend --> read_consistency
    CassandraBackend --> _get_connection
    CassandraBackend --> _store_result
    CassandraBackend --> _get_task_meta_for
    CassandraBackend --> buf_t
```
### Cassandra Backend Features

The `CassandraBackend` class [celery/backends/cassandra.py71-257](https://github.com/celery/celery/blob/4d068b56/celery/backends/cassandra.py#L71-L257) provides distributed result storage:

**Feature Support:**

-   `supports_autoexpire = True` - TTL-based automatic expiration [celery/backends/cassandra.py86](https://github.com/celery/celery/blob/4d068b56/celery/backends/cassandra.py#L86-L86)
-   Dual connection modes: standard clusters or AstraDB cloud bundles [celery/backends/cassandra.py104-110](https://github.com/celery/celery/blob/4d068b56/celery/backends/cassandra.py#L104-L110)
-   Consistency level configuration for read/write operations [celery/backends/cassandra.py117-125](https://github.com/celery/celery/blob/4d068b56/celery/backends/cassandra.py#L117-L125)

**Query Templates:** The backend defines CQL query templates as constants [celery/backends/cassandra.py37-64](https://github.com/celery/celery/blob/4d068b56/celery/backends/cassandra.py#L37-L64):

-   `Q_INSERT_RESULT` - Task result insertion with optional TTL
-   `Q_SELECT_RESULT` - Task result selection by task\_id
-   `Q_CREATE_RESULT_TABLE` - Table creation with clustering order
-   `Q_EXPIRES` - TTL clause template using `USING TTL {0}`

**Table Schema:** The backend creates tables using `Q_CREATE_RESULT_TABLE` [celery/backends/cassandra.py50-60](https://github.com/celery/celery/blob/4d068b56/celery/backends/cassandra.py#L50-L60):

```
CREATE TABLE {table} (
    task_id text,
    status text,
    result blob,
    date_done timestamp,
    traceback blob,
    children blob,
    PRIMARY KEY ((task_id), date_done)
) WITH CLUSTERING ORDER BY (date_done DESC);
```
**Connection Management:**

-   `_get_connection()` handles thread-safe connection setup with `threading.RLock()` [celery/backends/cassandra.py142-212](https://github.com/celery/celery/blob/4d068b56/celery/backends/cassandra.py#L142-L212)
-   Standard clusters created with `servers` list [celery/backends/cassandra.py155-159](https://github.com/celery/celery/blob/4d068b56/celery/backends/cassandra.py#L155-L159)
-   AstraDB cloud uses `secure_connect_bundle` from `bundle_path` [celery/backends/cassandra.py161-167](https://github.com/celery/celery/blob/4d068b56/celery/backends/cassandra.py#L161-L167)
-   Authentication via `cassandra.auth` providers [celery/backends/cassandra.py128-134](https://github.com/celery/celery/blob/4d068b56/celery/backends/cassandra.py#L128-L134)

**Operations:**

-   `_store_result()` executes prepared write statement with `buf_t()` encoding [celery/backends/cassandra.py214-226](https://github.com/celery/celery/blob/4d068b56/celery/backends/cassandra.py#L214-L226)
-   `_get_task_meta_for()` uses prepared read statement returning meta dictionary [celery/backends/cassandra.py231-248](https://github.com/celery/celery/blob/4d068b56/celery/backends/cassandra.py#L231-L248)
-   Auto-creates result table on first write operation [celery/backends/cassandra.py183-200](https://github.com/celery/celery/blob/4d068b56/celery/backends/cassandra.py#L183-L200)

Sources: [celery/backends/cassandra.py37-64](https://github.com/celery/celery/blob/4d068b56/celery/backends/cassandra.py#L37-L64) [celery/backends/cassandra.py86](https://github.com/celery/celery/blob/4d068b56/celery/backends/cassandra.py#L86-L86) [celery/backends/cassandra.py142-248](https://github.com/celery/celery/blob/4d068b56/celery/backends/cassandra.py#L142-L248)

## Elasticsearch Backend Implementation

The `ElasticsearchBackend` provides result storage using Elasticsearch with support for optimistic concurrency control and time-series indexing. It extends `KeyValueStoreBackend`.

### Elasticsearch Backend Architecture

```mermaid
flowchart TD
    ElasticsearchBackend["ElasticsearchBackend"]
    KeyValueStoreBackend["KeyValueStoreBackend"]
    elasticsearch_Elasticsearch["elasticsearch.Elasticsearch"]
    elastic_transport["elastic_transport"]
    index["index property"]
    doc_type["doc_type property"]
    scheme["scheme property"]
    host_port["host/port properties"]
    es_timeout["es_timeout"]
    es_max_retries["es_max_retries"]
    es_save_meta_as_text["es_save_meta_as_text"]
    get_method["get()"]
    _get_method["_get()"]
    set_method["set()"]
    _set_with_state["_set_with_state()"]
    _index_method["_index()"]
    _update_method["_update()"]
    delete_method["delete()"]
    mget_method["mget()"]
    ConflictError["elasticsearch.exceptions.ConflictError"]
    NotFoundError["elasticsearch.exceptions.NotFoundError"]
    seq_no["_seq_no"]
    primary_term["_primary_term"]
    if_seq_no["if_seq_no"]
    if_primary_term["if_primary_term"]
    states_SUCCESS["states.SUCCESS"]
    states_READY_STATES["states.READY_STATES"]
    states_UNREADY_STATES["states.UNREADY_STATES"]
    decode_result["decode_result()"]

    ElasticsearchBackend --> KeyValueStoreBackend
    ElasticsearchBackend --> elasticsearch_Elasticsearch
    ElasticsearchBackend --> elastic_transport
    ElasticsearchBackend --> index
    ElasticsearchBackend --> doc_type
    ElasticsearchBackend --> scheme
    ElasticsearchBackend --> host_port
    ElasticsearchBackend --> es_timeout
    ElasticsearchBackend --> es_max_retries
    ElasticsearchBackend --> es_save_meta_as_text
    ElasticsearchBackend --> get_method
    ElasticsearchBackend --> _get_method
    ElasticsearchBackend --> set_method
    ElasticsearchBackend --> _set_with_state
    ElasticsearchBackend --> _index_method
    ElasticsearchBackend --> _update_method
    ElasticsearchBackend --> delete_method
    ElasticsearchBackend --> mget_method
    _update --> method_ConflictError
    _update --> method_NotFoundError
    _update --> method_seq_no
    _update --> method_primary_term
    _update --> method_if_seq_no
    _update --> method_if_primary_term
    _update --> method_states_SUCCESS
    _update --> method_states_READY_STATES
    _update --> method_states_UNREADY_STATES
    _update --> method_decode_result
```
### Elasticsearch Concurrency Control

The `ElasticsearchBackend` class [celery/backends/elasticsearch.py30-284](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L30-L284) implements sophisticated concurrency control:

**Optimistic Locking Implementation:** The `_update()` method [celery/backends/elasticsearch.py167-231](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L167-L231) uses Elasticsearch's optimistic concurrency control:

-   Retrieves current `_seq_no` and `_primary_term` from existing document [celery/backends/elasticsearch.py201-202](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L201-L202)
-   Updates with `if_primary_term` and `if_seq_no` parameters [celery/backends/elasticsearch.py211](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L211-L211) [celery/backends/elasticsearch.py219](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L219-L219)
-   Raises `ConflictError` if sequence number/primary term mismatch [celery/backends/elasticsearch.py226-230](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L226-L230)

**State Validation Logic:** The `_update()` method implements state protection [celery/backends/elasticsearch.py187-197](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L187-L197):

-   Decodes existing result with `decode_result()` to check current state [celery/backends/elasticsearch.py188](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L188-L188)
-   Returns `{'result': 'noop'}` if existing state is `SUCCESS` [celery/backends/elasticsearch.py192-194](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L192-L194)
-   Prevents `UNREADY_STATES` from overwriting `READY_STATES` [celery/backends/elasticsearch.py195-197](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L195-L197)

**Document Operations:**

-   `_set_with_state()` attempts `_index()` with `op_type: 'create'`, falls back to `_update()` on conflict [celery/backends/elasticsearch.py128-142](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L128-L142)
-   `_index()` handles both regular and doc\_type modes [celery/backends/elasticsearch.py147-165](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L147-L165)
-   Document structure includes `@timestamp` field with UTC timezone [celery/backends/elasticsearch.py131-133](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L131-L133)

**Serialization Modes:**

-   `es_save_meta_as_text` configuration controls serialization [celery/backends/elasticsearch.py87](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L87-L87)
-   `encode()`/`decode()` methods handle both text and object modes [celery/backends/elasticsearch.py233-255](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L233-L255)
-   Object mode preserves result and traceback as nested objects [celery/backends/elasticsearch.py239-243](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L239-L243)

**Exception Handling:**

-   `exception_safe_to_retry()` method identifies retryable exceptions [celery/backends/elasticsearch.py90-102](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L90-L102)
-   Handles `ApiError` status codes (401, 409, 500, 502, 504) and `TransportError` [celery/backends/elasticsearch.py91-101](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L91-L101)

Sources: [celery/backends/elasticsearch.py87](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L87-L87) [celery/backends/elasticsearch.py90-102](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L90-L102) [celery/backends/elasticsearch.py128-142](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L128-L142) [celery/backends/elasticsearch.py167-231](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L167-L231) [celery/backends/elasticsearch.py233-255](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L233-L255)

## Backend Configuration and Selection

Different backends are selected via the `result_backend` configuration setting using URL schemes or backend names:

### Backend URL Schemes

| Backend | URL Scheme | Example |
| --- | --- | --- |
| Redis | `redis://` | `redis://localhost:6379/0` |
| MongoDB | `mongodb://` | `mongodb://user:pass@host/database` |
| Cassandra | `cassandra://` | `cassandra://` (uses config settings) |
| Elasticsearch | `elasticsearch://` | `elasticsearch://localhost:9200/index` |

### Backend-Specific Configuration

**Redis Configuration:**

```
result_backend = 'redis://localhost:6379/0'
redis_max_connections = 20
redis_socket_timeout = 30.0
redis_socket_keepalive = True
redis_backend_health_check_interval = 30
```
**MongoDB Configuration:**

```
result_backend = 'mongodb://localhost:27017/celery'
mongodb_backend_settings = {
    'database': 'celery',
    'taskmeta_collection': 'celery_taskmeta',
    'groupmeta_collection': 'celery_groupmeta',
    'max_pool_size': 10,
    'options': {'maxPoolSize': 10}
}
```
**Cassandra Configuration:**

```
result_backend = 'cassandra://'
cassandra_servers = ['localhost']
cassandra_keyspace = 'celery'
cassandra_table = 'task_results'
cassandra_entry_ttl = 86400  # 1 day TTL
cassandra_read_consistency = 'LOCAL_QUORUM'
cassandra_write_consistency = 'LOCAL_QUORUM'
cassandra_auth_provider = 'PlainTextAuthProvider'
cassandra_auth_kwargs = {'username': 'user', 'password': 'pass'}
```
**Elasticsearch Configuration:**

```
result_backend = 'elasticsearch://localhost:9200/celery'
elasticsearch_timeout = 10
elasticsearch_max_retries = 3
elasticsearch_retry_on_timeout = False
elasticsearch_save_meta_as_text = True
```
Sources: [celery/backends/mongodb.py91-117](https://github.com/celery/celery/blob/4d068b56/celery/backends/mongodb.py#L91-L117) [celery/backends/cassandra.py88-141](https://github.com/celery/celery/blob/4d068b56/celery/backends/cassandra.py#L88-L141) [celery/backends/elasticsearch.py75-87](https://github.com/celery/celery/blob/4d068b56/celery/backends/elasticsearch.py#L75-L87)

## Backend Implementation Comparison

| Feature | Cache Backend | RPC Backend |
| --- | --- | --- |
| **Base Class** | `KeyValueStoreBackend` | `Backend + AsyncBackendMixin` |
| **Storage** | External cache servers | AMQP messages |
| **Persistence** | Configurable | Not persistent |
| **Chord Support** | ✅ Full support | ❌ Not supported |
| **Group Operations** | ✅ Supported | ❌ Not supported |
| **Auto Expiration** | ✅ TTL-based | ✅ Message expiration |
| **Native Join** | ✅ Batch operations | ✅ Direct consumption |
| **Increment Ops** | ✅ Atomic incr | ❌ Not applicable |
| **Result Reloading** | ✅ Supported | ❌ Not supported |
| **Async Results** | Via polling | ✅ Event-driven |

### Memory and Resource Usage

**Cache Backend:**

-   Uses `_DUMMY_CLIENT_CACHE = LRUCache(limit=5000)` [celery/backends/cache.py25](https://github.com/celery/celery/blob/4d068b56/celery/backends/cache.py#L25-L25) for in-memory storage
-   Shared between threads for memory efficiency
-   Supports connection pooling through cache client libraries

**RPC Backend:**

-   Maintains `_out_of_band` dictionary for buffering unexpected results [celery/backends/rpc.py124](https://github.com/celery/celery/blob/4d068b56/celery/backends/rpc.py#L124-L124)
-   Uses `BacklogLimitExceeded` protection with default limit of 1000 messages [celery/backends/rpc.py232](https://github.com/celery/celery/blob/4d068b56/celery/backends/rpc.py#L232-L232)
-   One queue per client process via `app.thread_oid` [celery/backends/rpc.py340-342](https://github.com/celery/celery/blob/4d068b56/celery/backends/rpc.py#L340-L342)

Sources: [celery/backends/cache.py23-25](https://github.com/celery/celery/blob/4d068b56/celery/backends/cache.py#L23-L25) [celery/backends/rpc.py232-282](https://github.com/celery/celery/blob/4d068b56/celery/backends/rpc.py#L232-L282) [celery/backends/rpc.py339-342](https://github.com/celery/celery/blob/4d068b56/celery/backends/rpc.py#L339-L342)
