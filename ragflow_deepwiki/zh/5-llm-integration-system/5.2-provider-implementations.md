# 提供商实现 (Provider Implementations)

相关源文件：

-   [api/apps/llm_app.py](https://github.com/infiniflow/ragflow/blob/80a16e71/api/apps/llm_app.py)
-   [api/db/init_data.py](https://github.com/infiniflow/ragflow/blob/80a16e71/api/db/init_data.py)
-   [api/db/services/llm_service.py](https://github.com/infiniflow/ragflow/blob/80a16e71/api/db/services/llm_service.py)
-   [conf/llm_factories.json](https://github.com/infiniflow/ragflow/blob/80a16e71/conf/llm_factories.json)
-   [docs/references/supported_models.mdx](https://github.com/infiniflow/ragflow/blob/80a16e71/docs/references/supported_models.mdx)
-   [rag/llm/__init__.py](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/__init__.py)
-   [rag/llm/chat_model.py](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/chat_model.py)
-   [rag/llm/cv_model.py](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/cv_model.py)
-   [rag/llm/embedding_model.py](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/embedding_model.py)
-   [rag/llm/rerank_model.py](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/rerank_model.py)
-   [rag/llm/sequence2txt_model.py](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/sequence2txt_model.py)
-   [rag/llm/tts_model.py](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/tts_model.py)
-   [web/src/assets/svg/llm/n1n.svg](https://github.com/infiniflow/ragflow/blob/80a16e71/web/src/assets/svg/llm/n1n.svg)
-   [web/src/constants/llm.ts](https://github.com/infiniflow/ragflow/blob/80a16e71/web/src/constants/llm.ts)
-   [web/src/pages/user-setting/setting-model/constant.ts](https://github.com/infiniflow/ragflow/blob/80a16e71/web/src/pages/user-setting/setting-model/constant.ts)
-   [web/src/utils/common-util.ts](https://github.com/infiniflow/ragflow/blob/80a16e71/web/src/utils/common-util.ts)

本文档描述了 RAGFlow 中 LLM 提供商的实现架构，涵盖了 6 种模型类型（聊天、嵌入、重排序、图像转文本、TTS、语音转文本）下的 40 多个提供商。每个提供商通过继承自特定模型类型的基类来实现标准接口。有关工厂注册模式和动态加载机制的信息，请参阅 [模型工厂模式与注册 (Model Factory Pattern and Registration)](/zh/5-llm-integration-system/5.1-model-factory-pattern-and-registration)。有关配置和用量追踪的信息，请参阅 [租户配置与用量追踪 (Tenant Configuration and Usage Tracking)](/zh/5-llm-integration-system/5.4-tenant-configuration-and-usage-tracking)。

**范围**：本页面重点关注具体的提供商实现、其基类合约、身份验证模式以及特殊处理要求。不涵盖错误处理（参见 [错误处理与重试逻辑 (Error Handling and Retry Logic)](/zh/5-llm-integration-system/5.3-error-handling-and-retry-logic)）或工具调用能力（参见 [工具调用与函数使用 (Tool Calling and Function Use)](/zh/5-llm-integration-system/5.5-tool-calling-and-function-use)）。

---

## 模型类型基类 (Model Type Base Classes)

6 种模型类型中的每一种都定义了一个抽象基类，所有提供商必须实现这些基类。这些基类确立了接口合约并提供了通用功能。

### 聊天模型基类

[rag/llm/chat_model.py:65-488](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/chat_model.py#L65-L488) 中的 `Base` 类为具有 OpenAI 兼容 API 的聊天模型定义了接口：

**核心方法：**
-   `async_chat(system, history, gen_conf)` - 单次补全
-   `async_chat_streamly(system, history, gen_conf)` - 流式补全
-   `async_chat_with_tools(system, history, gen_conf)` - 工具调用支持
-   `bind_tools(toolcall_session, tools)` - 附加工具以进行函数调用

**标准配置处理：**
-   `_clean_conf(gen_conf)` - 过滤允许的参数（temperature, max_tokens, top_p 等）
-   `_classify_error(error)` - 将异常映射到 `LLMErrorCode` 枚举值
-   `_should_retry(error_code)` - 确定错误是否为暂时性错误

### 嵌入模型基类

[rag/llm/embedding_model.py:37-51](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/embedding_model.py#L37-L51) 中的 `Base` 类定义了嵌入模型的简单接口：

**核心方法：**
-   `encode(texts: list)` - 批量编码文档，返回 `(embeddings, token_count)`
-   `encode_queries(text: str)` - 带有特殊处理的单条查询编码

大多数嵌入提供商继承此基类并重写这两个方法。典型的模式是将请求按 16 个一组进行分批，并使用 `common.token_utils` 中的 `truncate()` 限制输入长度。

### 重排序模型基类

[rag/llm/rerank_model.py:28-54](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/rerank_model.py#L28-L54) 中的 `Base` 类提供重排序功能：

**核心方法：**
-   `similarity(query: str, texts: list)` - 返回 `(rank_scores, token_count)`，其中 `rank_scores` 是包含每个文本相关性评分的 numpy 数组。

### 视觉模型基类

[rag/llm/cv_model.py:42-187](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/cv_model.py#L42-L187) 中的 `Base` 类处理图像转文本：

**核心方法：**
-   `describe(image)` - 使用默认提示词生成图像描述
-   `describe_with_prompt(image, prompt)` - 使用自定义提示词生成描述
-   `async_chat(system, history, gen_conf, images)` - 带有图像上下文的聊天
-   `async_chat_streamly(system, history, gen_conf, images)` - 带有图像的流式聊天

### TTS 模型基类

[rag/llm/tts_model.py:65-78](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/tts_model.py#L65-L78) 中的 `Base` 类提供文本转语音功能：

**核心方法：**
-   `tts(text: str) -> Generator[bytes, None, None]` - 产出音频块，随后返回 Token 计数作为最终值。

### 语音转文本模型基类

[rag/llm/sequence2txt_model.py:31-50](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/sequence2txt_model.py#L31-L50) 中的 `Base` 类处理音频转录：

**核心方法：**
-   `transcription(audio_path, **kwargs)` - 返回 `(transcribed_text, token_count)`

---

## 提供商实现类别 (Provider Implementation Categories)

### OpenAI 兼容提供商

最大的一类提供商使用 OpenAI 的客户端库配合自定义的 `base_url`。它们继承自基类 `Base`（对于视觉模型则是 `GptV4`），通常只需要最少的定制。

| 提供商类 | 工厂名称 | 基础 URL | 备注 |
| --- | --- | --- | --- |
| `Base` (默认) | N/A | 可配置 | 带有 OpenAI/AsyncOpenAI 客户端的基础实现 |
| `XinferenceChat` | `Xinference` | `{base_url}/v1` | 在用户提供的 URL 后追加 `/v1` |
| `HuggingFaceChat` | `HuggingFace` | `{base_url}/v1` | 去除模型名称中的 `___` 后缀 |
| `LmStudioChat` | `LM-Studio` | `{base_url}/v1` | 使用 `"lm-studio"` 作为 API 密钥 |
| `OpenAI_APIChat` | `["VLLM", "OpenAI-API-Compatible"]` | 用户提供 | 通用的兼容性包装器 |

**数据源**：[rag/llm/chat_model.py:490-753](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/chat_model.py#L490-L753)

### 原生 SDK 提供商

某些提供商使用其原生 SDK 而非 OpenAI 客户端：

-   **MistralChat**: 使用 `mistralai.client.MistralClient` [rag/llm/chat_model.py:670-722](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/chat_model.py#L670-L722)
-   **ReplicateChat**: 使用 `replicate` SDK 并从最后 5 条历史消息构建提示词 [rag/llm/chat_model.py:755-794](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/chat_model.py#L755-L794)
-   **腾讯混元 (HunyuanChat)**: 使用腾讯云 SDK 配合特殊的消息格式（首字母大写的键）[rag/llm/chat_model.py:796-872](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/chat_model.py#L796-L872)

---

## 特殊身份验证模式 (Special Authentication Patterns)

### 火山引擎 (VolcEngine) 身份验证

火山引擎使用特殊的验证模式，API 密钥以包含 ARK API 密钥和端点 ID 的 JSON 格式存储。在初始化时解析 JSON 并将 `ark_api_key` 传递给 OpenAI 客户端。

**数据源**：[rag/llm/chat_model.py:655-668](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/chat_model.py#L655-L668) [api/apps/llm_app.py:144-147](https://github.com/infiniflow/ragflow/blob/80a16e71/api/apps/llm_app.py#L144-L147)

### Bedrock 多模式身份验证

AWS Bedrock 支持三种身份验证模式：`access_key_secret`（直接凭据）、`iam_role`（通过 STS 获取角色）和 `assume_role`（默认 AWS 凭据链）。

**数据源**：[rag/llm/embedding_model.py:461-503](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/embedding_model.py#L461-L503)

### Azure OpenAI 身份验证

Azure 在端点 URL 之外还需要一个单独的 API 版本参数。它使用 `openai.lib.azure.AzureOpenAI` 客户端。

**数据源**：[rag/llm/embedding_model.py:153-162](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/embedding_model.py#L153-L162)

---

## 模型能力矩阵 (Model Capability Matrix)

下表展示了各大提供商支持的模型类型（摘自 `conf/llm_factories.json`）：

| 提供商 | 聊天 | 嵌入 | 重排序 | 图像转文本 | TTS | 语音转文本 |
| --- | --- | --- | --- | --- | --- | --- |
| OpenAI | ✓ | ✓ |  | ✓ | ✓ | ✓ |
| Anthropic | ✓ |  |  |  |  |  |
| 通义千问 | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |
| 智谱 AI | ✓ | ✓ |  | ✓ |  |  |
| Azure-OpenAI | ✓ | ✓ |  | ✓ |  | ✓ |
| Gemini | ✓ | ✓ |  | ✓ |  |  |
| Bedrock | ✓ | ✓ |  |  |  |  |
| Ollama | ✓ | ✓ |  | ✓ |  |  |
| Xinference | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |
| Jina |  | ✓ | ✓ |  |  |  |
| Cohere | ✓ | ✓ | ✓ | ✓ |  |  |
| Mistral | ✓ | ✓ |  |  |  |  |

**数据源**：[conf/llm_factories.json:1-200](https://github.com/infiniflow/ragflow/blob/80a16e71/conf/llm_factories.json#L1-L200)

---

## 模型名称处理约定 (Model Name Handling Conventions)

多个提供商使用后缀模式来区分部署类型：

-   `___LocalAI`: 用于 LocalAI
-   `___HuggingFace`: 用于 HuggingFace
-   `___OpenAI-API`: 用于 OpenAI-API-Compatible
-   `___VLLM`: 用于 VLLM

这些后缀在添加模型时被追加，而在提供商实现中，通过 `model_name.split("___")[0]` 将其剥离，以获取用于 API 调用的实际模型名称。

**数据源**：[api/apps/llm_app.py:162-172](https://github.com/infiniflow/ragflow/blob/80a16e71/api/apps/llm_app.py#L162-L172) [rag/llm/embedding_model.py:133](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/embedding_model.py#L133-L133)

---

## 提供商特殊特性 (Special Provider Features)

### 推理模型 (QwQ)
基础聊天实现包含了对输出带有 `<think>` 标签的推理模型（如 QwQ）的特殊处理逻辑，支持在流式传输时剥离推理内容。

### 视频总结 (QWen)
QWenCV 包含使用 DashScope 的 `MultiModalConversation` API 进行视频处理的能力。

### 多向量嵌入 (Jina v4)
Jina 的 v4 嵌入模型支持多向量表示，其中每个 token 都有一个嵌入，最终的分块嵌入计算为各向量的均值。

**数据源**：[rag/llm/chat_model.py:447-461](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/chat_model.py#L447-L461) [rag/llm/cv_model.py:261-306](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/cv_model.py#L261-L306) [rag/llm/embedding_model.py:354-410](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/llm/embedding_model.py#L354-L410)
