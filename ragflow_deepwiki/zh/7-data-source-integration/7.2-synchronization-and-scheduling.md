# 7.2 同步与调度 (Synchronization and Scheduling)

相关源文件：

- [api/apps/connector_app.py](https://github.com/infiniflow/ragflow/blob/80a16e71/api/apps/connector_app.py)
- [api/db/db_models.py](https://github.com/infiniflow/ragflow/blob/80a16e71/api/db/db_models.py)
- [api/db/services/connector_service.py](https://github.com/infiniflow/ragflow/blob/80a16e71/api/db/services/connector_service.py)
- [api/db/services/document_service.py](https://github.com/infiniflow/ragflow/blob/80a16e71/api/db/services/document_service.py)
- [api/db/services/knowledgebase_service.py](https://github.com/infiniflow/ragflow/blob/80a16e71/api/db/services/knowledgebase_service.py)
- [api/db/services/task_service.py](https://github.com/infiniflow/ragflow/blob/80a16e71/api/db/services/task_service.py)
- [rag/svr/sync_data_source.py](https://github.com/infiniflow/ragflow/blob/80a16e71/rag/svr/sync_data_source.py)

本文档描述了 RAGFlow 中的数据源同步与调度系统。该系统负责定期将外部数据源（如 S3、Notion、Gmail 等）中的文档摄取到数据集中。

## 概述 (Overview)

同步系统允许 RAGFlow 根据预设周期自动从 20 多个外部数据源拉取文档。它支持全量同步（重索引）和增量同步（仅轮询自上次同步以来的更改），并具备并发任务执行、超时管理和进度追踪功能。

**核心职责：**
- 执行来自外部数据源的同步任务。
- 支持基于文档修改时间戳的增量轮询。
- 通过信号量限制管理并发任务执行。
- 通过 `SyncLogsService` 追踪同步进度和错误。
- 在完成后调度下一个同步周期。
- 处理基于 OAuth 的连接器的凭据刷新。

## 任务生命周期与状态管理 (Task Lifecycle and State Management)

**任务状态枚举：**
- `UNSTART ("0")`：任务已创建但尚未开始。
- `RUNNING ("1")`：正在执行。
- `CANCEL ("2")`：用户已取消。
- `DONE ("3")`：成功完成。
- `FAIL ("4")`：失败并报错。
- `SCHEDULE ("5")`：已调度至未来执行。

**任务执行流：**
1.  **开始**：调用 `SyncLogsService.start()` 将任务标记为运行中。
2.  **执行**：在指定的超时时间内执行任务逻辑。
3.  **超时处理**：如果发生 `asyncio.TimeoutError`，则将状态标记为 `FAIL`。
4.  **异常处理**：捕获完整的堆栈追踪信息和错误消息。
5.  **完成**：标记为 `DONE` 并调度下一次运行。

## 增量同步 vs 全量同步 (Incremental vs Full Synchronization)

系统通过 `reindex` 标志和 `poll_range_start` 时间戳来确定同步模式：

| 模式 | 条件 | 行为 |
| --- | --- | --- |
| **全量同步** | `reindex == "1"` 或 `poll_range_start` 为空 | 从源头检索所有文档 |
| **增量同步** | `reindex != "1"` 且 `poll_range_start` 不为空 | 仅检索自上次同步以来修改的文档 |

## 文档批处理 (Document Batch Processing)

同步系统按批次处理文档，以优化内存消耗并实现增量进度追踪：
1.  **批次迭代**：通过异步生成器遍历文档批次。
2.  **追踪更新时间**：记录每个批次中最新的文档更新时间。
3.  **格式转换**：将连接器对象转换为统一的字典格式。
4.  **去重与解析**：检查重复、上传文件到 MinIO、创建数据库记录，并根据需要排队解析任务。
5.  **更新进度**：记录文档数量、处理的时间范围、错误消息及失败文档数。
6.  **更新检查点**：维护同步位置，确保下次增量同步从正确的时间点开始。

## 调度与下次同步计算 (Scheduling and Next Sync Calculation)

任务成功完成后，系统会自动计算下次同步的时间戳：
1.  初始 `next_update` 设置为 1970 年或上次轮询的开始时间。
2.  每个批次处理后，使用批次中最大的 `doc_updated_at` 更新 `next_update`。
3.  所有批次完成后，将该值存入 `poll_range_start`。
4.  调用 `SyncLogsService.schedule()` 创建下一个周期性任务。

## 并发控制 (Concurrency Control)

为了防止资源耗尽，同步系统将并发执行的任务数量限制在 `MAX_CONCURRENT_TASKS`（默认为 5）。该限制通过 `asyncio.Semaphore` 在 `sync_data_source.py` 中实现。

## 系统集成点 (System Integration Points)

-   **`SyncLogsService`**：追踪同步执行进度并调度下次运行。
-   **`ConnectorService`**：管理连接器配置和凭据更新。
-   **`KnowledgebaseService`**：处理文档去重、上传及解析任务创建。
-   **Redis 任务队列**：接收解析任务。
-   **文档处理流水线**：在同步完成后对文档进行解析和切片。
