# Text Splitting and Chunking

Relevant source files

-   [backend/open\_webui/config.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/config.py)
-   [backend/open\_webui/main.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/main.py)
-   [backend/open\_webui/retrieval/loaders/datalab\_marker.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/retrieval/loaders/datalab_marker.py)
-   [backend/open\_webui/retrieval/loaders/external\_document.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/retrieval/loaders/external_document.py)
-   [backend/open\_webui/retrieval/loaders/external\_web.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/retrieval/loaders/external_web.py)
-   [backend/open\_webui/retrieval/loaders/main.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/retrieval/loaders/main.py)
-   [backend/open\_webui/retrieval/loaders/mineru.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/retrieval/loaders/mineru.py)
-   [backend/open\_webui/retrieval/loaders/mistral.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/retrieval/loaders/mistral.py)
-   [backend/open\_webui/retrieval/utils.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/retrieval/utils.py)
-   [backend/open\_webui/routers/retrieval.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/routers/retrieval.py)
-   [backend/open\_webui/utils/middleware.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/utils/middleware.py)
-   [src/lib/apis/retrieval/index.ts](https://github.com/open-webui/open-webui/blob/a7271532/src/lib/apis/retrieval/index.ts)
-   [src/lib/components/admin/Settings/Documents.svelte](https://github.com/open-webui/open-webui/blob/a7271532/src/lib/components/admin/Settings/Documents.svelte)
-   [src/lib/components/admin/Settings/WebSearch.svelte](https://github.com/open-webui/open-webui/blob/a7271532/src/lib/components/admin/Settings/WebSearch.svelte)

This page documents the text splitting and chunking system used in Open WebUI's RAG (Retrieval-Augmented Generation) pipeline. Text splitting is the process of breaking down large documents into smaller, semantically meaningful chunks that can be efficiently embedded and retrieved.

For information about document content extraction that occurs before chunking, see [Content Extraction Engines](/open-webui/open-webui/7.2-content-extraction-engines). For information about embedding generation that occurs after chunking, see [Embedding Generation](/open-webui/open-webui/7.4-embedding-generation).

## Purpose and Scope

Text splitting is a critical component of the RAG system that transforms extracted document content into appropriately-sized chunks for vector embedding. This page covers:

-   Available text splitter implementations
-   Chunk size and overlap configuration
-   How different splitters handle various document types
-   Integration with the document ingestion pipeline

## System Overview

The chunking system sits between content extraction and embedding generation in the RAG pipeline. After a document's text content is extracted, it must be divided into chunks that are:

1.  Small enough to fit within embedding model token limits
2.  Large enough to contain meaningful semantic context
3.  Appropriately overlapped to prevent information loss at chunk boundaries

```mermaid
flowchart TD
    Extract["Content Extraction(Tika, Docling, etc.)"]
    Split["Text Splitting(RecursiveCharacter,Token, MarkdownHeader)"]
    Embed["Embedding Generation(SentenceTransformers,OpenAI, Ollama)"]
    Store["Vector Storage(ChromaDB, Qdrant, etc.)"]
    Config["ConfigurationCHUNK_SIZECHUNK_OVERLAPTEXT_SPLITTERTIKTOKEN_ENCODING_NAME"]

    Extract --> Split
    Split --> Embed
    Embed --> Store
    Config --> Split
```
**Sources:** [backend/open\_webui/routers/retrieval.py32-36](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/routers/retrieval.py#L32-L36) [backend/open\_webui/config.py252-253](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/config.py#L252-L253) [backend/open\_webui/main.py888-890](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/main.py#L888-L890)

## Configuration Parameters

The chunking system is configured through persistent configuration values that can be modified via the admin settings UI.

| Parameter | Environment Variable | Default | Purpose |
| --- | --- | --- | --- |
| `CHUNK_SIZE` | `CHUNK_SIZE` | 1500 | Maximum number of characters per chunk |
| `CHUNK_OVERLAP` | `CHUNK_OVERLAP` | 100 | Number of overlapping characters between chunks |
| `TEXT_SPLITTER` | `RAG_TEXT_SPLITTER` | `"recursive"` | Splitter type: `"recursive"`, `"token"`, or `"markdown_header"` |
| `TIKTOKEN_ENCODING_NAME` | `TIKTOKEN_ENCODING_NAME` | `"cl100k_base"` | Encoding for token-based splitting |

```mermaid
flowchart TD
    EnvVars["Environment VariablesCHUNK_SIZECHUNK_OVERLAPRAG_TEXT_SPLITTER"]
    Database["DatabaseConfig Table"]
    Redis["Redis Cache(if enabled)"]
    AppConfig["AppConfig Classapp.state.config"]
    API["Retrieval API/retrieval/config"]
    SettingsUI["Settings/Documents.svelteChunking Settings Section"]

    EnvVars --> Database
    Database --> AppConfig
    Redis --> AppConfig
    AppConfig --> API
    API --> SettingsUI
    SettingsUI --> API
```
**Sources:** [backend/open\_webui/config.py1-50](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/config.py#L1-L50) [backend/open\_webui/main.py888-893](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/main.py#L888-L893) [backend/open\_webui/routers/retrieval.py249-261](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/routers/retrieval.py#L249-L261) [backend/open\_webui/routers/retrieval.py443-504](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/routers/retrieval.py#L443-L504)

## Text Splitter Types

Open WebUI uses LangChain's text splitter implementations to handle different document structures and requirements.

### Recursive Character Text Splitter

The default and most versatile splitter that recursively tries different separators to find natural breakpoints.

```mermaid
flowchart TD
    Input["Document Text"]
    TryNewline["Try Split onDouble Newline"]
    TrySpace["Try Split onSingle Newline"]
    TrySentence["Try Split onPeriod + Space ."]
    TryChar["Split byCharacter Count"]
    CheckSize1["Size OK?"]
    CheckSize2["Size OK?"]
    CheckSize3["Size OK?"]
    Output["Chunks withCHUNK_SIZE limitCHUNK_OVERLAP applied"]

    Input --> TryNewline
    TryNewline --> CheckSize1
    CheckSize1 --> TrySpace
    CheckSize1 --> Output
    TrySpace --> CheckSize2
    CheckSize2 --> TrySentence
    CheckSize2 --> Output
    TrySentence --> CheckSize3
    CheckSize3 --> TryChar
    CheckSize3 --> Output
    TryChar --> Output
```
**Characteristics:**

-   Recursively tries separators in order: `["\n\n", "\n", " ", ""]`
-   Attempts to preserve paragraph and sentence boundaries
-   Falls back to character-level splitting if necessary
-   Best for general-purpose text documents

**Sources:** [backend/open\_webui/routers/retrieval.py32-36](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/routers/retrieval.py#L32-L36)

### Token Text Splitter

Uses tiktoken tokenization to split text based on token count rather than character count, ensuring chunks fit within model token limits.

```mermaid
flowchart TD
    Input["Document Text"]
    Tokenize["Tokenize withtiktokenTIKTOKEN_ENCODING_NAME"]
    Count["Count Tokensin Sequence"]
    Split["Split atCHUNK_SIZE tokens"]
    Overlap["ApplyCHUNK_OVERLAP tokens"]
    Decode["Decode TokensBack to Text"]
    Output["Token-alignedChunks"]

    Input --> Tokenize
    Tokenize --> Count
    Count --> Split
    Split --> Overlap
    Overlap --> Decode
    Decode --> Output
```
**Characteristics:**

-   Splits by token count, not character count
-   Ensures compatibility with embedding model token limits
-   Uses tiktoken encodings (e.g., `"cl100k_base"` for GPT-4)
-   More precise for transformer-based models
-   Token count directly maps to model input size

**Configuration:**

-   Token counting determined by `TIKTOKEN_ENCODING_NAME`
-   Common encodings: `"cl100k_base"` (GPT-4), `"p50k_base"` (GPT-3)

**Sources:** [backend/open\_webui/routers/retrieval.py32-36](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/routers/retrieval.py#L32-L36) [backend/open\_webui/config.py889](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/config.py#L889-L889) [backend/open\_webui/main.py889](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/main.py#L889-L889)

### Markdown Header Text Splitter

Specialized splitter that preserves Markdown document structure by splitting on header boundaries.

```mermaid
flowchart TD
    Input["Markdown Document"]
    ParseHeaders["Parse HeaderHierarchy# ## ### etc."]
    IdentifySections["Identify Sectionsby Header Levels"]
    ExtractMetadata["Extract Header Pathas Metadataheadings: [H1, H2, H3]"]
    SplitSections["Split at HeaderBoundaries"]
    ApplySize["Apply CHUNK_SIZEto Large Sections"]
    Output["Chunks withHeader Metadata"]
    MetadataExample["metadata:headings: ['Intro', 'Features', 'Authentication']source: 'docs.md'"]

    Input --> ParseHeaders
    ParseHeaders --> IdentifySections
    IdentifySections --> ExtractMetadata
    ExtractMetadata --> SplitSections
    SplitSections --> ApplySize
    ApplySize --> Output
    Output --> MetadataExample
```
**Characteristics:**

-   Splits on Markdown headers (`#`, `##`, `###`, etc.)
-   Preserves document hierarchy in chunk metadata
-   Stores header path as `metadata["headings"]` list
-   Ideal for structured documentation and API docs
-   Maintains semantic document structure

**Metadata Enhancement:** The header path is stored in chunk metadata and used during hybrid search for improved retrieval relevance (see [Retrieval Strategies](/open-webui/open-webui/7.6-retrieval-strategies)).

**Sources:** [backend/open\_webui/routers/retrieval.py32-36](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/routers/retrieval.py#L32-L36) [backend/open\_webui/retrieval/utils.py189-193](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/retrieval/utils.py#L189-L193)

## Chunking in the Document Pipeline

The text splitting process is integrated into the broader document ingestion pipeline, which processes uploaded files and web-scraped content.

```mermaid
flowchart TD
    Upload["File Uploador URL Input"]
    Extract["Content ExtractionLoader.load()returns List[Document]"]
    Engine["Content ExtractionEngine"]
    External["ExternalDocumentLoader"]
    Tika["TikaLoader"]
    Docling["DoclingLoader"]
    Marker["DatalabMarkerLoader"]
    MinerU["MinerULoader"]
    Mistral["MistralLoader"]
    Native["Native LoadersPyPDFLoader, CSVLoader, etc."]
    Raw["Raw DocumentsList[Document]page_content + metadata"]
    Split["Text SplittingApply SplitterBased on TEXT_SPLITTER"]
    Chunks["Document ChunksList[Document]with overlap"]
    Embed["Generate EmbeddingsEMBEDDING_FUNCTION"]
    Store["Store in Vector DBVECTOR_DB_CLIENT.upsert()"]

    Upload --> Extract
    Extract --> Engine
    Engine --> External
    Engine --> Tika
    Engine --> Docling
    Engine --> Marker
    Engine --> MinerU
    Engine --> Mistral
    Engine --> Native
    External --> Raw
    Tika --> Raw
    Docling --> Raw
    Marker --> Raw
    MinerU --> Raw
    Mistral --> Raw
    Native --> Raw
    Raw --> Split
    Split --> Chunks
    Chunks --> Embed
    Embed --> Store
```
**Sources:** [backend/open\_webui/retrieval/loaders/main.py184-201](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/retrieval/loaders/main.py#L184-L201) [backend/open\_webui/routers/retrieval.py32-36](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/routers/retrieval.py#L32-L36)

## Chunk Overlap Strategy

Chunk overlap prevents information loss at chunk boundaries by including a sliding window of text from the previous chunk.

```
Document: "The quick brown fox jumps over the lazy dog. The dog was sleeping under a tree."

CHUNK_SIZE = 40 characters
CHUNK_OVERLAP = 10 characters

Chunk 1: "The quick brown fox jumps over the l"
          |----------- 40 chars -----------|

Chunk 2:              "over the lazy dog. The dog was slee"
          |--10 overlap--|---- 30 new -----|

Chunk 3:                            "dog was sleeping under a tree."
                        |--10 overlap--|-- remaining --|
```
**Visual Representation:**

```mermaid
flowchart TD
    D1["Paragraph 1500 chars"]
    D2["Paragraph 2800 chars"]
    D3["Paragraph 3600 chars"]
    C1["Chunk 10-500(P1 complete)"]
    C2["Chunk 2400-900(P1 end + P2 start)100 char overlap"]
    C3["Chunk 3800-1400(P2 end + P3 start)100 char overlap"]
    C4["Chunk 41300-1900(P3 end)100 char overlap"]

    D1 --> C1
    D1 --> C2
    D2 --> C2
    D2 --> C3
    D3 --> C3
    D3 --> C4
```
**Benefits of Overlap:**

1.  **Prevents Context Loss:** Sentences or concepts split across chunk boundaries remain retrievable
2.  **Improves Retrieval:** Multiple chunks may contain the same key information, increasing recall
3.  **Maintains Coherence:** Overlapping context helps LLMs understand chunk relationships

**Trade-offs:**

-   Increased storage requirements (duplicate text)
-   More chunks to process during embedding
-   Higher computational cost

**Sources:** [backend/open\_webui/config.py252-253](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/config.py#L252-L253) [backend/open\_webui/main.py892](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/main.py#L892-L892)

## Text Enrichment for Hybrid Search

When hybrid search is enabled, chunk metadata is enriched with additional context to improve BM25 (keyword-based) retrieval performance.

```mermaid
flowchart TD
    StdText["page_content:'Machine learning modelsrequire training data...'"]
    StdMeta["metadata:name: 'ml_guide.pdf'title: 'ML Guide'source: '/docs/ml_guide.pdf'"]
    EnrichText["enriched_text:'Machine learning modelsrequire training data...Filename: ml_guide.pdfml guide pdf ml guide pdfTitle: ML GuideSource: /docs/ml_guide.pdf'"]
    EnrichMeta["metadata:(unchanged)"]
    BM25["BM25RetrieverKeyword MatchingEnhanced by metadata"]

    StdText --> EnrichText
    StdMeta --> EnrichText
    EnrichText --> BM25
```
**Enrichment Process:**

The `get_enriched_texts()` function in [backend/open\_webui/retrieval/utils.py170-205](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/retrieval/utils.py#L170-L205) adds metadata fields to chunk text:

1.  **Filename** (repeated twice for extra weight)
2.  **Title** (if available)
3.  **Section headings** (from Markdown splitter metadata)
4.  **Source URL/path**
5.  **Snippet** (for web search results)

This enrichment happens when:

-   `ENABLE_RAG_HYBRID_SEARCH` is enabled
-   `ENABLE_RAG_HYBRID_SEARCH_ENRICHED_TEXTS` is enabled
-   Querying with `query_doc_with_hybrid_search()`

**Sources:** [backend/open\_webui/retrieval/utils.py170-205](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/retrieval/utils.py#L170-L205) [backend/open\_webui/retrieval/utils.py240-244](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/retrieval/utils.py#L240-L244)

## Splitter Selection and Usage

The text splitter is selected based on the `TEXT_SPLITTER` configuration value and instantiated when processing documents.

```mermaid
flowchart TD
    Config["app.state.configTEXT_SPLITTER"]
    Check["TEXT_SPLITTERvalue?"]
    Recursive["RecursiveCharacterTextSplitterchunk_size=CHUNK_SIZEchunk_overlap=CHUNK_OVERLAPseparators=['', '', ' ', '']"]
    Token["TokenTextSplitterchunk_size=CHUNK_SIZEchunk_overlap=CHUNK_OVERLAPencoding_name=TIKTOKEN_ENCODING_NAME"]
    Markdown["MarkdownHeaderTextSplitterheaders_to_split_on=[  ('#', 'Header 1'),  ('##', 'Header 2'),  ('###', 'Header 3')]+ RecursiveCharacterTextSplitterfor large sections"]
    Default["RecursiveCharacterTextSplitter(fallback)"]
    Documents["Input DocumentsList[Document]"]
    Split["splitter.split_documents()orsplitter.split_text()"]
    Chunks["Output ChunksList[Document]"]

    Config --> Check
    Check --> Recursive
    Check --> Token
    Check --> Markdown
    Check --> Default
    Documents --> Split
    Recursive --> Split
    Token --> Split
    Markdown --> Split
    Default --> Split
    Split --> Chunks
```
**Implementation Note:** While the configuration exposes splitter selection via `TEXT_SPLITTER`, the actual instantiation and usage of these splitters occurs in the document processing code that was truncated in the provided files. The splitters are imported from `langchain_text_splitters` at [backend/open\_webui/routers/retrieval.py32-36](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/routers/retrieval.py#L32-L36)

**Sources:** [backend/open\_webui/routers/retrieval.py32-36](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/routers/retrieval.py#L32-L36) [backend/open\_webui/config.py888-890](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/config.py#L888-L890) [backend/open\_webui/routers/retrieval.py496-498](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/routers/retrieval.py#L496-L498)

## Integration with Embeddings

After text splitting, chunks are prepared for embedding generation. The chunked documents flow into the embedding system with appropriate batch sizing.

```mermaid
flowchart TD
    Chunks["List[Document]N chunkseach with page_contentand metadata"]
    Batch["Batch Documentsbatch_size=RAG_EMBEDDING_BATCH_SIZE"]
    EmbedFunc["EMBEDDING_FUNCTIONgenerate embeddingswith prefix:RAG_EMBEDDING_CONTENT_PREFIX"]
    Async["ENABLE_ASYNC_EMBEDDING?"]
    SyncEmbed["SynchronousEmbedding"]
    AsyncEmbed["AsynchronousEmbeddingBatch Processing"]
    Prepare["Prepare Vectorsids, documents,metadatas, embeddings"]
    Upsert["VECTOR_DB_CLIENT.upsert()collection_name"]

    Chunks --> Batch
    Batch --> EmbedFunc
    EmbedFunc --> Async
    Async --> SyncEmbed
    Async --> AsyncEmbed
    SyncEmbed --> Prepare
    AsyncEmbed --> Prepare
    Prepare --> Upsert
```
**Embedding Process:**

1.  Chunks are batched according to `RAG_EMBEDDING_BATCH_SIZE`
2.  `RAG_EMBEDDING_CONTENT_PREFIX` is prepended to chunk text (if configured)
3.  Embedding function generates vector representations
4.  Vectors are stored with chunk metadata in the vector database

**Batch Size Considerations:**

-   Smaller batches: Lower memory usage, more API calls
-   Larger batches: Higher throughput, higher memory usage
-   Default: 1 (conservative, works for all systems)

**Sources:** [backend/open\_webui/main.py894-897](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/main.py#L894-L897) [backend/open\_webui/config.py234-235](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/config.py#L234-L235) [backend/open\_webui/routers/retrieval.py258-260](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/routers/retrieval.py#L258-L260)

## Configuration via Admin UI

The chunking settings are exposed through the admin settings interface, allowing runtime configuration without code changes.

```mermaid
flowchart TD
    DocumentsUI["Settings/Documents.svelteDocuments Tab"]
    ChunkSizeInput["CHUNK_SIZE InputNumber Field"]
    ChunkOverlapInput["CHUNK_OVERLAP InputNumber Field"]
    SplitterSelect["TEXT_SPLITTER SelectDropdown: recursive/token/markdown"]
    GetConfig["GET /retrieval/configReturns current settings"]
    UpdateConfig["POST /retrieval/config/updateUpdates settings"]
    AppConfig["app.state.configPersistentConfig objects"]
    ConfigDB["Config TableJSON data column"]
    RedisCache["Redis Cache(if enabled)"]

    DocumentsUI --> GetConfig
    ChunkSizeInput --> DocumentsUI
    ChunkOverlapInput --> DocumentsUI
    SplitterSelect --> DocumentsUI
    DocumentsUI --> UpdateConfig
    GetConfig --> AppConfig
    UpdateConfig --> AppConfig
    AppConfig --> ConfigDB
    AppConfig --> RedisCache
```
**Configuration Flow:**

1.  Admin opens Settings → Documents
2.  UI fetches current config via `GET /retrieval/config`
3.  Admin modifies CHUNK\_SIZE, CHUNK\_OVERLAP, or TEXT\_SPLITTER
4.  On save, `POST /retrieval/config/update` persists changes
5.  Changes are immediately available for new document uploads
6.  Existing embedded documents are not automatically re-chunked

**Important:** Changing chunking parameters does not automatically re-process existing documents. To apply new settings to existing files, use the "Reindex Knowledge Files" feature in the admin settings.

**Sources:** [src/lib/components/admin/Settings/Documents.svelte1-274](https://github.com/open-webui/open-webui/blob/a7271532/src/lib/components/admin/Settings/Documents.svelte#L1-L274) [backend/open\_webui/routers/retrieval.py443-504](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/routers/retrieval.py#L443-L504) [src/lib/apis/retrieval/index.ts3-91](https://github.com/open-webui/open-webui/blob/a7271532/src/lib/apis/retrieval/index.ts#L3-L91)

## Best Practices

### Choosing Chunk Size

| Document Type | Recommended CHUNK\_SIZE | Reasoning |
| --- | --- | --- |
| Technical documentation | 1000-1500 chars | Preserves code blocks and technical explanations |
| General articles | 1500-2000 chars | Maintains paragraph-level coherence |
| Chat logs / Conversations | 500-1000 chars | Keeps individual exchanges intact |
| Academic papers | 2000-3000 chars | Preserves complex arguments and citations |
| Code files | 1000-1500 chars | Keeps function/class definitions together |

### Choosing Chunk Overlap

**General Rule:** Set overlap to 10-15% of chunk size.

-   Too small (<5%): Risk of losing context at boundaries
-   Too large (>30%): Excessive redundancy, wasted storage
-   Sweet spot: 10-20% of CHUNK\_SIZE

**Examples:**

-   CHUNK\_SIZE=1500 → CHUNK\_OVERLAP=150-225
-   CHUNK\_SIZE=2000 → CHUNK\_OVERLAP=200-300

### Choosing Text Splitter

| Splitter | Best For | Avoid For |
| --- | --- | --- |
| `recursive` | General documents, mixed content | Highly structured docs with strict formatting |
| `token` | Precise token control, working with specific models | General use (unnecessary precision overhead) |
| `markdown_header` | Technical docs, wikis, structured markdown | Unstructured text, non-markdown documents |

**Sources:** [backend/open\_webui/routers/retrieval.py32-36](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/routers/retrieval.py#L32-L36) [backend/open\_webui/config.py888-893](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/config.py#L888-L893)
