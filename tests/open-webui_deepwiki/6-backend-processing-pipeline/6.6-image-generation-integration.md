# Image Generation Integration

Relevant source files

-   [backend/open\_webui/config.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/config.py)
-   [backend/open\_webui/main.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/main.py)
-   [backend/open\_webui/retrieval/loaders/datalab\_marker.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/retrieval/loaders/datalab_marker.py)
-   [backend/open\_webui/retrieval/loaders/external\_document.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/retrieval/loaders/external_document.py)
-   [backend/open\_webui/retrieval/loaders/external\_web.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/retrieval/loaders/external_web.py)
-   [backend/open\_webui/retrieval/loaders/main.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/retrieval/loaders/main.py)
-   [backend/open\_webui/retrieval/loaders/mineru.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/retrieval/loaders/mineru.py)
-   [backend/open\_webui/retrieval/loaders/mistral.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/retrieval/loaders/mistral.py)
-   [backend/open\_webui/retrieval/utils.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/retrieval/utils.py)
-   [backend/open\_webui/routers/retrieval.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/routers/retrieval.py)
-   [backend/open\_webui/utils/middleware.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/utils/middleware.py)
-   [src/lib/apis/retrieval/index.ts](https://github.com/open-webui/open-webui/blob/a7271532/src/lib/apis/retrieval/index.ts)
-   [src/lib/components/admin/Settings/Documents.svelte](https://github.com/open-webui/open-webui/blob/a7271532/src/lib/components/admin/Settings/Documents.svelte)
-   [src/lib/components/admin/Settings/WebSearch.svelte](https://github.com/open-webui/open-webui/blob/a7271532/src/lib/components/admin/Settings/WebSearch.svelte)

The Image Generation Integration system provides automated image creation and editing capabilities within the chat interface. When enabled, the system intercepts user requests to generate or edit images, processes them through configured backend engines (DALL-E, Stable Diffusion, Gemini, ComfyUI), and displays results inline in the conversation.

For web search integration, see [Web Search Integration](/open-webui/open-webui/6.5-web-search-integration). For tool execution, see [Tool Execution System](/open-webui/open-webui/6.3-tool-execution-system).

## System Architecture

The image generation system operates as a middleware handler in the chat processing pipeline, intercepting requests before they reach the LLM and fulfilling them with generated images.

```mermaid
flowchart TD
    UserMsg["User Message(in chat)"]
    ProcessPayload["process_chat_payloadmiddleware.py"]
    ImageHandler["chat_image_generation_handlermiddleware.py:755-929"]
    CheckEnabled["Check ENABLE_IMAGE_GENERATIONconfig.py:1089"]
    CheckEdit["Check ENABLE_IMAGE_EDITfor existing images"]
    PromptGen["generate_image_prompt(optional enhancement)"]
    OpenAI["image_generationsrouters/images.pyIMAGES_OPENAI_API_*"]
    Gemini["Gemini ImagenIMAGES_GEMINI_API_*"]
    Auto1111["AUTOMATIC1111Stable DiffusionAUTOMATIC1111_BASE_URL"]
    ComfyUI["ComfyUICOMFYUI_BASE_URL"]
    EventEmitter["event_emitterstatus updates"]
    FileResponse["Files eventwith image URLs"]
    SystemMsg["System messagecontext injection"]

    UserMsg --> ProcessPayload
    ProcessPayload --> ImageHandler
    ImageHandler --> CheckEnabled
    CheckEnabled --> CheckEdit
    CheckEdit --> OpenAI
    CheckEdit --> PromptGen
    PromptGen --> OpenAI
    ImageHandler --> OpenAI
    ImageHandler --> Gemini
    ImageHandler --> Auto1111
    ImageHandler --> ComfyUI
    OpenAI --> EventEmitter
    EventEmitter --> FileResponse
    EventEmitter --> SystemMsg
```
**Sources:** [backend/open\_webui/utils/middleware.py755-929](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/utils/middleware.py#L755-L929) [backend/open\_webui/main.py1088-1124](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/main.py#L1088-L1124) [backend/open\_webui/config.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/config.py)

## Configuration System

Image generation is configured through environment variables or persistent configuration, supporting four distinct backend engines with separate configurations for generation and editing.

### Generation Configuration

| Configuration Key | Type | Purpose |
| --- | --- | --- |
| `ENABLE_IMAGE_GENERATION` | Boolean | Master switch for image generation |
| `ENABLE_IMAGE_PROMPT_GENERATION` | Boolean | Use LLM to enhance image prompts |
| `IMAGE_GENERATION_ENGINE` | String | Backend: `openai`, `gemini`, `automatic1111`, `comfyui` |
| `IMAGE_GENERATION_MODEL` | String | Model identifier for the selected engine |
| `IMAGE_SIZE` | String | Default image dimensions (e.g., `1024x1024`) |
| `IMAGE_STEPS` | Integer | Inference steps (for diffusion models) |

### Engine-Specific Configuration

```mermaid
flowchart TD
    CF_URL["COMFYUI_BASE_URLconfig.py:1109"]
    CF_KEY["COMFYUI_API_KEYconfig.py:1110"]
    CF_WF["COMFYUI_WORKFLOWconfig.py:1111"]
    CF_NODES["COMFYUI_WORKFLOW_NODESconfig.py:1112"]
    A11_URL["AUTOMATIC1111_BASE_URLconfig.py:1105"]
    A11_AUTH["AUTOMATIC1111_API_AUTHconfig.py:1106"]
    A11_PARAMS["AUTOMATIC1111_PARAMSconfig.py:1107"]
    GEM_URL["IMAGES_GEMINI_API_BASE_URLconfig.py:1101"]
    GEM_KEY["IMAGES_GEMINI_API_KEYconfig.py:1102"]
    GEM_METHOD["IMAGES_GEMINI_ENDPOINT_METHODconfig.py:1103"]
    OAI_URL["IMAGES_OPENAI_API_BASE_URLconfig.py:1096"]
    OAI_KEY["IMAGES_OPENAI_API_KEYconfig.py:1098"]
    OAI_VER["IMAGES_OPENAI_API_VERSIONconfig.py:1097"]
    OAI_PARAMS["IMAGES_OPENAI_API_PARAMSconfig.py:1099"]
```
**Sources:** [backend/open\_webui/main.py146-180](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/main.py#L146-L180) [backend/open\_webui/config.py1088-1124](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/config.py#L1088-L1124)

### Edit Configuration

The system maintains separate configuration for image editing operations, which apply when the chat contains existing images:

| Configuration Key | Purpose |
| --- | --- |
| `ENABLE_IMAGE_EDIT` | Enable image editing functionality |
| `IMAGE_EDIT_ENGINE` | Backend engine for editing (same options as generation) |
| `IMAGE_EDIT_MODEL` | Model identifier for editing |
| `IMAGE_EDIT_SIZE` | Output dimensions for edited images |
| `IMAGES_EDIT_OPENAI_API_BASE_URL` | OpenAI edit endpoint |
| `IMAGES_EDIT_GEMINI_API_BASE_URL` | Gemini edit endpoint |
| `IMAGES_EDIT_COMFYUI_BASE_URL` | ComfyUI edit endpoint |

**Sources:** [backend/open\_webui/main.py167-179](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/main.py#L167-L179) [backend/open\_webui/config.py1115-1124](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/config.py#L1115-L1124)

## Middleware Handler Integration

The `chat_image_generation_handler` function integrates into the chat processing pipeline as a middleware component that intercepts requests and fulfills them with generated images.

### Handler Registration

```mermaid
flowchart TD
    ChatRequest["Chat RequestPOST /api/chat/*"]
    ProcessPayload["process_chat_payloadmiddleware.py"]
    ToolsHandler["chat_completion_tools_handlermiddleware.py:286"]
    MemoryHandler["chat_memory_handlermiddleware.py:516"]
    WebSearchHandler["chat_web_search_handlermiddleware.py:555"]
    ImageGenHandler["chat_image_generation_handlermiddleware.py:755"]
    LLMProxy["LLM Backend Proxy"]
    Skip["Skip LLM callreturn early"]

    ChatRequest --> ProcessPayload
    ProcessPayload --> ToolsHandler
    ToolsHandler --> MemoryHandler
    MemoryHandler --> WebSearchHandler
    WebSearchHandler --> ImageGenHandler
    ImageGenHandler --> LLMProxy
    ImageGenHandler --> Skip
```
**Sources:** [backend/open\_webui/utils/middleware.py755-929](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/utils/middleware.py#L755-L929) [backend/open\_webui/utils/middleware.py494](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/utils/middleware.py#L494-L494)

### Handler Execution Flow

The handler follows a multi-stage process to determine whether to generate or edit images:

```mermaid
flowchart TD
    Start["chat_image_generation_handlerinvoked"]
    CheckChatID["Validate chat_idand event_emittermiddleware.py:759-763"]
    GetMessageList["Retrieve message historyfrom Chats.get_chat_by_id_and_user_idor from form_datamiddleware.py:765-778"]
    ExtractImages["get_images_from_messagesmiddleware.py:718-731"]
    HasImages["Has existingimages?"]
    CheckEditEnabled["Check ENABLE_IMAGE_EDITconfig.py:1115"]
    CallEditAPI["image_editsrouters/images.pyEditImageFormmiddleware.py:799-807"]
    EditSuccess["Emit files eventwith edited imagesmiddleware.py:816-829"]
    EditContext["Inject system message:'image has been edited'middleware.py:831"]
    CheckPromptGen["Check ENABLE_IMAGE_PROMPT_GENERATIONconfig.py:1090"]
    EnhancePrompt["generate_image_prompttasks.pymiddleware.py:858-884"]
    CallGenAPI["image_generationsrouters/images.pyCreateImageFormmiddleware.py:887-896"]
    GenSuccess["Emit files eventwith generated imagesmiddleware.py:898-909"]
    GenContext["Inject system message:'image has been generated'middleware.py:911"]
    CatchError["Exception handlermiddleware.py:833-852"]
    ErrorEmit["Emit error statusmiddleware.py:842-850"]
    ErrorContext["Inject error contextto system messagemiddleware.py:852"]

    Start --> CheckChatID
    CheckChatID --> GetMessageList
    GetMessageList --> ExtractImages
    ExtractImages --> HasImages
    HasImages --> CheckEditEnabled
    CheckEditEnabled --> CallEditAPI
    CallEditAPI --> EditSuccess
    EditSuccess --> EditContext
    CallEditAPI --> CatchError
    HasImages --> CheckPromptGen
    CheckPromptGen --> EnhancePrompt
    CheckPromptGen --> CallGenAPI
    EnhancePrompt --> CallGenAPI
    CallGenAPI --> GenSuccess
    GenSuccess --> GenContext
    CallGenAPI --> CatchError
    CatchError --> ErrorEmit
    ErrorEmit --> ErrorContext
```
**Sources:** [backend/open\_webui/utils/middleware.py755-929](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/utils/middleware.py#L755-L929)

## Prompt Enhancement System

When `ENABLE_IMAGE_PROMPT_GENERATION` is enabled, the system uses an LLM to enhance user prompts before image generation, improving output quality.

### Enhancement Process

The enhancement process extracts the user's intent and expands it into a more detailed, effective prompt for the image generation model:

1.  **Extract user message** - Get the last user message from conversation history [middleware.py780](https://github.com/open-webui/open-webui/blob/a7271532/middleware.py#L780-L780)
2.  **Call LLM task endpoint** - Invoke `generate_image_prompt` with current chat context [middleware.py858-865](https://github.com/open-webui/open-webui/blob/a7271532/middleware.py#L858-L865)
3.  **Parse JSON response** - Extract enhanced prompt from structured output [middleware.py867-880](https://github.com/open-webui/open-webui/blob/a7271532/middleware.py#L867-L880)
4.  **Fallback on error** - Use original user message if enhancement fails [middleware.py882-884](https://github.com/open-webui/open-webui/blob/a7271532/middleware.py#L882-L884)

The enhancement uses the configured `TASK_MODEL` with a specialized prompt template defined in `IMAGE_PROMPT_GENERATION_PROMPT_TEMPLATE`.

**Sources:** [backend/open\_webui/utils/middleware.py856-885](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/utils/middleware.py#L856-L885) [backend/open\_webui/main.py432](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/main.py#L432-L432)

## Event Emission Protocol

The handler communicates progress and results through the WebSocket event system, sending structured events to the frontend for real-time UI updates.

### Event Types

```mermaid
flowchart TD
    StatusStart["type: 'status'description: 'Creating image'done: falsemiddleware.py:769-773"]
    StatusDone["type: 'status'description: 'Image created'done: truemiddleware.py:810-814"]
    StatusError["type: 'status'description: 'Error...'done: truemiddleware.py:842-850"]
    FilesEvent["type: 'files'data.files: [  {type: 'image', url: '...'}]middleware.py:816-829"]

    StatusStart --> StatusDone
    StatusStart --> StatusError
    StatusDone --> FilesEvent
```
**Sources:** [backend/open\_webui/utils/middleware.py769-850](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/utils/middleware.py#L769-L850)

### System Message Context Injection

After successful image generation or editing, the handler injects a context message into the chat's system messages to inform the LLM about the generated image:

**Success context:**

```
<context>The requested image has been edited and created and is now being shown to the user. Let them know that it has been generated.</context>
```
[middleware.py831](https://github.com/open-webui/open-webui/blob/a7271532/middleware.py#L831-L831)

**Error context:**

```
<context>Image generation was attempted but failed. The system is currently unable to generate the image. Tell the user that the following error occurred: {error_message}</context>
```
[middleware.py852](https://github.com/open-webui/open-webui/blob/a7271532/middleware.py#L852-L852)

This allows the LLM to provide appropriate conversational responses acknowledging the image operation.

**Sources:** [backend/open\_webui/utils/middleware.py831](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/utils/middleware.py#L831-L831) [backend/open\_webui/utils/middleware.py852](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/utils/middleware.py#L852-L852)

## Image Extraction from Messages

The system searches backward through message history to find images attached to previous messages, supporting up to 2 sets of images for editing operations.

```mermaid
flowchart TD
    GetImages["get_images_from_messagesmiddleware.py:718-731"]
    ReverseLoop["Iterate messagesin reverse order"]
    CheckFiles["Check message.filesfor each message"]
    ExtractURL["Extract file.urlif file.type == 'image'"]
    Handler["chat_image_generation_handler"]
    LimitImages["Limit to 2 image setsmiddleware.py:788-792"]
    PassToEdit["Pass to image_editsEditImageFormmiddleware.py:801"]

    GetImages --> ReverseLoop
    ReverseLoop --> CheckFiles
    CheckFiles --> ExtractURL
    Handler --> GetImages
    GetImages --> LimitImages
    LimitImages --> PassToEdit
```
**Sources:** [backend/open\_webui/utils/middleware.py718-731](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/utils/middleware.py#L718-L731) [backend/open\_webui/utils/middleware.py783-792](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/utils/middleware.py#L783-L792)

## Backend Engine Routing

Image generation and editing requests are routed to the appropriate backend based on the configured `IMAGE_GENERATION_ENGINE` or `IMAGE_EDIT_ENGINE`. Each engine has its own API contract and capabilities.

### Generation Routing

The `image_generations` function in `routers/images.py` handles routing to the configured generation engine:

```mermaid
flowchart TD
    GenRequest["CreateImageForm{prompt, size, n, etc}"]
    Router["image_generationsrouters/images.py"]
    CheckEngine["Check IMAGE_GENERATION_ENGINEconfig"]
    OAI["POST to IMAGES_OPENAI_API_BASE_URL/images/generations"]
    OAIAuth["Authorization: Bearer {key}"]
    OAIResp["Parse response.data[]extract b64_json or url"]
    A11["POST to AUTOMATIC1111_BASE_URL/sdapi/v1/txt2img"]
    A11Auth["Basic Auth if configured"]
    A11Params["Merge AUTOMATIC1111_PARAMS"]
    A11Resp["Parse images[] arraydecode base64"]
    CF["POST to COMFYUI_BASE_URL/prompt"]
    CFWorkflow["Load COMFYUI_WORKFLOWsubstitute parameters"]
    CFNodes["Update COMFYUI_WORKFLOW_NODESwith prompt/size"]
    CFPoll["Poll /history/{prompt_id}for completion"]
    CFResp["Download output images"]

    GenRequest --> Router
    Router --> CheckEngine
    CheckEngine --> OAI
    CheckEngine --> A11
    CheckEngine --> CF
    OAI --> OAIAuth
    OAIAuth --> OAIResp
    A11 --> A11Auth
    A11Auth --> A11Params
    A11Params --> A11Resp
    CF --> CFWorkflow
    CFWorkflow --> CFNodes
    CFNodes --> CFPoll
    CFPoll --> CFResp
```
**Sources:** [backend/open\_webui/routers/images.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/routers/images.py) (referenced in imports), [backend/open\_webui/main.py1088-1112](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/main.py#L1088-L1112)

### Edit Routing

The `image_edits` function handles image editing operations with similar routing logic:

```mermaid
flowchart TD
    EditRequest["EditImageForm{prompt, image[], mask?}"]
    Router["image_editsrouters/images.py"]
    OAIEdit["POST to IMAGES_EDIT_OPENAI_API_BASE_URL/images/edits"]
    OAIMultipart["multipart/form-dataimage, prompt, mask"]
    GemEdit["POST to IMAGES_EDIT_GEMINI_API_BASE_URLgenerateContent"]
    GemInline["Inline image as base64in request body"]
    CFEdit["POST to IMAGES_EDIT_COMFYUI_BASE_URL"]
    CFEditWF["Load IMAGES_EDIT_COMFYUI_WORKFLOW"]
    CFImg2Img["Use img2img workflowwith source image"]

    EditRequest --> Router
    Router --> OAIEdit
    Router --> GemEdit
    Router --> CFEdit
    OAIEdit --> OAIMultipart
    GemEdit --> GemInline
    CFEdit --> CFEditWF
    CFEditWF --> CFImg2Img
```
**Sources:** [backend/open\_webui/utils/middleware.py799-807](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/utils/middleware.py#L799-L807) [backend/open\_webui/main.py1115-1124](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/main.py#L1115-L1124)

## Image URL Management

Generated images are returned as URLs that can be either external API URLs or base64 data URLs. The system handles conversion and storage through the file management system.

### URL Processing Flow

```mermaid
flowchart TD
    APIResp["API returns imageas URL or base64"]
    CheckType["URL type?"]
    DataURL["data:image/png;base64,... format"]
    HttpURL["https://... format"]
    Convert["get_image_url_from_base64files.py"]
    SaveFile["Save to storage provider(local/S3/GCS/Azure)"]
    GenURL["Generate /api/v1/files/ URL"]
    FileMetadata["Store metadata:- chat_id- message_id- session_id"]
    UserOwnership["Associate with user.id"]

    APIResp --> CheckType
    CheckType --> DataURL
    CheckType --> HttpURL
    DataURL --> Convert
    Convert --> SaveFile
    SaveFile --> GenURL
    GenURL --> FileMetadata
    FileMetadata --> UserOwnership
```
When images are converted from base64, the system calls `get_image_url_from_base64` which:

1.  Extracts base64 data from data URL
2.  Creates a file entry in the database
3.  Saves the binary content to the configured storage provider
4.  Returns a `/api/v1/files/<file_id>` URL

**Sources:** [backend/open\_webui/utils/middleware.py748](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/utils/middleware.py#L748-L748) [backend/open\_webui/utils/files.py](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/utils/files.py) (referenced in imports)

## Integration with Chat Completion

The image generation handler modifies the request payload and response to integrate seamlessly with the chat completion flow.

### Request Modification

After successful image generation, the handler:

1.  **Adds files to metadata** - Stores image URLs in `form_data['metadata']['files']` for persistence [middleware.py645-673](https://github.com/open-webui/open-webui/blob/a7271532/middleware.py#L645-L673)
2.  **Injects system message** - Adds context about generated image to help LLM respond appropriately [middleware.py831](https://github.com/open-webui/open-webui/blob/a7271532/middleware.py#L831-L831)
3.  **Returns modified form\_data** - Allows chat pipeline to continue with augmented request

### Response Bypass

When image generation is successful, the handler effectively bypasses the LLM call by:

1.  Emitting the image files event directly to the frontend
2.  Providing context in the system message for the LLM to acknowledge
3.  Allowing the normal chat completion to proceed with minimal token usage

The LLM receives a system message indicating the image was generated and can provide a conversational acknowledgment without needing to see the actual image.

**Sources:** [backend/open\_webui/utils/middleware.py755-929](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/utils/middleware.py#L755-L929)

## Error Handling and Recovery

The system implements comprehensive error handling at multiple levels to ensure graceful degradation.

### Handler-Level Error Handling

```mermaid
flowchart TD
    TryBlock["try: image generation/editingmiddleware.py:798-831"]
    ExceptBlock["except Exception as emiddleware.py:832"]
    CheckHTTP["isinstance(e,HTTPException)?"]
    ExtractDetail["Extract e.detailerror message"]
    StringDetail["Convert to string"]
    EmitError["Emit status event:type='status'done=truemiddleware.py:842-850"]
    InjectContext["Inject error intosystem messagemiddleware.py:852"]
    ContinuePipeline["Allow pipeline to continueto LLM"]
    LLMResponse["LLM provides responseabout failure"]

    TryBlock --> ExceptBlock
    ExceptBlock --> CheckHTTP
    CheckHTTP --> ExtractDetail
    CheckHTTP --> StringDetail
    ExtractDetail --> EmitError
    StringDetail --> EmitError
    EmitError --> InjectContext
    InjectContext --> ContinuePipeline
    ContinuePipeline --> LLMResponse
```
### Backend-Specific Errors

Each backend engine may return different error types:

| Engine | Common Errors | Handling |
| --- | --- | --- |
| OpenAI | API key invalid, rate limit, NSFW content filter | Extract from `response.json()['error']['message']` |
| AUTOMATIC1111 | Connection refused, model not loaded | HTTP connection errors, timeouts |
| ComfyUI | Invalid workflow, missing nodes, workflow execution failure | Poll status for errors |
| Gemini | Safety filters, quota exceeded | Parse API error response |

**Sources:** [backend/open\_webui/utils/middleware.py832-852](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/utils/middleware.py#L832-L852)

## Configuration Persistence

Image generation configuration is managed through the `AppConfig` system with Redis-backed synchronization for distributed deployments.

### Configuration Updates

When image generation settings are modified through the admin UI:

1.  Configuration written to `app.state.config.IMAGE_GENERATION_ENGINE` etc. [main.py1088-1112](https://github.com/open-webui/open-webui/blob/a7271532/main.py#L1088-L1112)
2.  `AppConfig.__setattr__` triggers database save [config.py251-260](https://github.com/open-webui/open-webui/blob/a7271532/config.py#L251-L260)
3.  Redis key `{prefix}:config:IMAGE_GENERATION_ENGINE` updated for cross-instance sync [config.py259-260](https://github.com/open-webui/open-webui/blob/a7271532/config.py#L259-L260)
4.  Other instances read from Redis on next config access [config.py267-283](https://github.com/open-webui/open-webui/blob/a7271532/config.py#L267-L283)

This ensures configuration changes propagate across all backend instances in a horizontally scaled deployment.

**Sources:** [backend/open\_webui/config.py224-284](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/config.py#L224-L284) [backend/open\_webui/main.py1088-1124](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/main.py#L1088-L1124)
