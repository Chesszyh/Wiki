# Docker 部署选项

相关源文件

-   [LICENSE](https://github.com/open-webui/open-webui/blob/a7271532/LICENSE)
-   [README.md](https://github.com/open-webui/open-webui/blob/a7271532/README.md)
-   [TROUBLESHOOTING.md](https://github.com/open-webui/open-webui/blob/a7271532/TROUBLESHOOTING.md)
-   [docs/apache.md](https://github.com/open-webui/open-webui/blob/a7271532/docs/apache.md)
-   [src/lib/components/chat/Settings/About.svelte](https://github.com/open-webui/open-webui/blob/a7271532/src/lib/components/chat/Settings/About.svelte)
-   [src/lib/constants.ts](https://github.com/open-webui/open-webui/blob/a7271532/src/lib/constants.ts)

## 目的与范围

本文档解释了 Open WebUI 可用的不同 Docker 部署拓扑结构，包括捆绑式 Ollama 容器、独立容器配置、GPU 支持以及纯云端部署。每种拓扑结构都针对不同的用例进行了优化，涵盖了从简单的单用户设置到生产环境的多容器编排。

---

## 部署拓扑概览

Open WebUI 支持六种主要部署模式，每种模式适用于不同的需求：

### 部署拓扑比较

```mermaid
flowchart TD
    G1["ghcr.io/open-webui/open-webui:cuda 或 :ollama 使用 --gpus"]
    G1Vol1["GPU 访问 --gpus all"]
    G1Vol2["卷"]
    C1["ghcr.io/open-webui/open-webui:main 仅 UI"]
    C1Cloud["OpenAI/Anthropic/Google 外部 API"]
    C1Vol["open-webui 卷"]
    S1["ghcr.io/open-webui/open-webui:main UI 容器 端口 3000:8080"]
    S2["ollama/ollama 或 外部 Ollama 端口 11434"]
    S1Vol["open-webui 卷"]
    B1["ghcr.io/open-webui/open-webui:ollama 单容器 UI + Ollama 内嵌"]
    B1Vol1["ollama 卷 /root/.ollama"]
    B1Vol2["open-webui 卷 /app/backend/data"]

    G1 --> G1Vol1
    G1 --> G1Vol2
    C1 --> C1Cloud
    C1 --> C1Vol
    S1 --> S2
    S1 --> S1Vol
    B1 --> B1Vol1
    B1 --> B1Vol2
```
**来源：** [README.md108-169](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L108-L169)

### 各拓扑适用场景

| 拓扑 | 最佳适用 | 注意事项 |
| --- | --- | --- |
| **捆绑式 Ollama** | 快速启动、单用户、开发 | 设置简单，镜像体积较大，单点故障域 |
| **独立容器** | 生产环境、可扩展性、资源隔离 | 部署灵活，独立扩展，需要网络配置 |
| **纯云端** | 无本地 GPU、API 优先、资源极简 | 资源需求低，产生 API 费用，依赖互联网 |
| **GPU 加速** | 高性能、大模型、高吞吐量 | 需要 NVIDIA GPU，需安装 CUDA 工具包 |
| **Kubernetes** | 企业级、高可用性、多租户 | 设置复杂，水平扩展，生产级韧性 |
| **开发环境** | 本地开发、热重载 | 前端和后端分开运行，使用 Vite 开发服务器 |

**来源：** [README.md86-176](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L86-L176)

---

## 选项 1：捆绑式 Ollama 部署

捆绑式部署通过使用 `:ollama` 镜像标签将 Open WebUI 和 Ollama 合并到一个容器中。这是最简单的部署选项，适合快速上手。

### 架构：捆绑式 Ollama 容器

```mermaid
flowchart TD
    UI["Open WebUI FastAPI + SvelteKit 端口 8080"]
    OllamaEmbedded["Ollama 进程 内部端口 11434"]
    Vol1["/root/.ollama Ollama 模型"]
    Vol2["/app/backend/data 用户数据 + SQLite"]
    Client["浏览器"]

    UI --> OllamaEmbedded
    OllamaEmbedded --> Vol1
    UI --> Vol2
    Client --> UI
```
**来源：** [README.md149-167](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L149-L167)

### 带 GPU 支持

```
docker run -d \
  -p 3000:8080 \
  --gpus=all \
  -v ollama:/root/.ollama \
  -v open-webui:/app/backend/data \
  --name open-webui \
  --restart always \
  ghcr.io/open-webui/open-webui:ollama
```
**关键配置：**

-   `--gpus=all` - 为 Ollama 模型推理启用 GPU 访问
-   `-v ollama:/root/.ollama` - 存储下载的 Ollama 模型
-   `-v open-webui:/app/backend/data` - 存储用户数据、聊天记录和 SQLite 数据库

**来源：** [README.md153-158](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L153-L158)

### 仅 CPU 部署

```
docker run -d \
  -p 3000:8080 \
  -v ollama:/root/.ollama \
  -v open-webui:/app/backend/data \
  --name open-webui \
  --restart always \
  ghcr.io/open-webui/open-webui:ollama
```
**来源：** [README.md160-165](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L160-L165)

### 捆绑式部署特点

| 方面 | 配置 |
| --- | --- |
| **镜像标签** | `ghcr.io/open-webui/open-webui:ollama` |
| **Ollama 位置** | 嵌入在容器内，内部通信 |
| **端口映射** | `3000:8080` (主机:容器) |
| **模型存储** | `/root/.ollama` 卷 |
| **用户数据** | `/app/backend/data` 卷 |
| **GPU 要求** | 可选；使用 `--gpus=all` 获取 GPU 访问权限 |
| **最佳适用** | 快速启动、单用户、开发环境 |

**来源：** [README.md149-167](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L149-L167)

---

## 选项 2：独立容器部署

独立容器拓扑在不同的容器中运行 Open WebUI 和 Ollama，或者连接到外部 Ollama 实例。这为分布式部署和资源隔离提供了灵活性。

### 架构：独立容器

```mermaid
flowchart TD
    UI["ghcr.io/open-webui/open-webui:main 端口 3000:8080"]
    Opt1["同一 Docker 主机 host.docker.internal:11434"]
    Opt2["不同服务器 https://example.com:11434"]
    Opt3["Docker 网络 ollama:11434"]
    Vol["open-webui:/app/backend/data"]

    UI --> Opt1
    UI --> Opt2
    UI --> Opt3
    UI --> Vol
```
**来源：** [README.md119-133](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L119-L133) [TROUBLESHOOTING.md6-8](https://github.com/open-webui/open-webui/blob/a7271532/TROUBLESHOOTING.md#L6-L8)

### Ollama 运行在同一主机

当 Ollama 运行在同一台主机上时：

```
docker run -d \
  -p 3000:8080 \
  --add-host=host.docker.internal:host-gateway \
  -v open-webui:/app/backend/data \
  --name open-webui \
  --restart always \
  ghcr.io/open-webui/open-webui:main
```
**关键配置：**

-   `--add-host=host.docker.internal:host-gateway` - 允许容器访问主机
-   默认 `OLLAMA_BASE_URL` 解析为 `http://host.docker.internal:11434`
-   Ollama 必须在主机的 `11434` 端口运行

**来源：** [README.md121-125](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L121-L125) [TROUBLESHOOTING.md13-19](https://github.com/open-webui/open-webui/blob/a7271532/TROUBLESHOOTING.md#L13-L19)

### Ollama 运行在不同服务器

当连接到远程服务器上的 Ollama 时：

```
docker run -d \
  -p 3000:8080 \
  -e OLLAMA_BASE_URL=https://example.com \
  -v open-webui:/app/backend/data \
  --name open-webui \
  --restart always \
  ghcr.io/open-webui/open-webui:main
```
**关键配置：**

-   `-e OLLAMA_BASE_URL=https://example.com` - 指向远程 Ollama 服务器
-   可以使用 HTTP 或 HTTPS
-   如果未指定，端口默认为 `11434`

**来源：** [README.md127-133](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L127-L133) [TROUBLESHOOTING.md31-35](https://github.com/open-webui/open-webui/blob/a7271532/TROUBLESHOOTING.md#L31-L35)

### 使用主机网络模式

为了解决连接问题，可以使用主机网络模式：

```
docker run -d \
  --network=host \
  -v open-webui:/app/backend/data \
  -e OLLAMA_BASE_URL=http://127.0.0.1:11434 \
  --name open-webui \
  --restart always \
  ghcr.io/open-webui/open-webui:main
```
**注意：** 使用 `--network=host` 时，端口从 `3000` 变为 `8080`。访问地址为 `http://localhost:8080`。

**来源：** [README.md183-189](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L183-L189) [TROUBLESHOOTING.md11-19](https://github.com/open-webui/open-webui/blob/a7271532/TROUBLESHOOTING.md#L11-L19)

### 独立容器特点

| 方面 | 配置 |
| --- | --- |
| **镜像标签** | `ghcr.io/open-webui/open-webui:main` |
| **Ollama 连接** | 通过 `OLLAMA_BASE_URL` 环境变量 |
| **网络选项** | 网桥 (默认)、主机或自定义网络 |
| **端口映射** | `3000:8080` (网桥) 或 `8080` (主机模式) |
| **用户数据** | `/app/backend/data` 卷 |
| **最佳适用** | 生产环境、分布式部署、独立扩展 |

**来源：** [README.md119-133](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L119-L133) [TROUBLESHOOTING.md6-19](https://github.com/open-webui/open-webui/blob/a7271532/TROUBLESHOOTING.md#L6-L19)

---

## 选项 3：GPU 加速部署

GPU 加速可以加快大模型的推理速度。Open WebUI 提供了支持 NVIDIA GPU 的 `:cuda` 镜像标签。

### 架构：GPU 访问

```mermaid
flowchart TD
    UI["Open WebUI"]
    GPUAccess["--gpus all CUDA 访问"]
    GPU["NVIDIA GPU 硬件"]
    NVRuntime["NVIDIA Container Runtime"]
    Vol["open-webui 卷"]

    GPUAccess --> NVRuntime
    NVRuntime --> GPU
    UI --> Vol
```
**来源：** [README.md135-139](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L135-L139)

### GPU 部署命令

```
docker run -d \
  -p 3000:8080 \
  --gpus all \
  --add-host=host.docker.internal:host-gateway \
  -v open-webui:/app/backend/data \
  --name open-webui \
  --restart always \
  ghcr.io/open-webui/open-webui:cuda
```
**关键配置：**

-   `--gpus all` - 授予访问主机上所有 GPU 的权限
-   `ghcr.io/open-webui/open-webui:cuda` - 启用 CUDA 的镜像
-   也可以使用 `--gpus '"device=0,1"'` 来指定具体的 GPU

**来源：** [README.md135-139](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L135-L139)

### GPU 支持的先决条件

在部署启用 GPU 的容器之前，请安装 NVIDIA Container Toolkit：

**在 Linux/WSL 上：**

```
# 添加 NVIDIA 软件包存储库
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
  sudo tee /etc/apt/sources.list.d/nvidia-docker.list

# 安装 nvidia-container-toolkit
sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit

# 重启 Docker
sudo systemctl restart docker
```
**来源：** [README.md117](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L117-L117)

### GPU 部署特点

| 方面 | 配置 |
| --- | --- |
| **镜像标签** | `ghcr.io/open-webui/open-webui:cuda` |
| **GPU 要求** | 支持 CUDA 的 NVIDIA GPU |
| **运行时要求** | 主机上已安装 NVIDIA Container Toolkit |
| **GPU 选择** | `--gpus all` 或 `--gpus '"device=0,1"'` |
| **性能** | 大模型推理速度显著提升 |
| **最佳适用** | 高吞吐量工作负载、大模型、生产用途 |

**来源：** [README.md117](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L117-L117) [README.md135-139](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L135-L139)

---

## 选项 4：纯云端部署

纯云端拓扑使用外部 LLM API（OpenAI、Anthropic、Google），不运行本地模型，从而最大限度地减少资源需求。

### 架构：纯云端

```mermaid
flowchart TD
    UI["ghcr.io/open-webui/open-webui:main 仅 UI"]
    Vol["open-webui 卷"]
    OpenAI["OpenAI API api.openai.com"]
    Anthropic["Anthropic API api.anthropic.com"]
    Google["Google AI generativelanguage.googleapis.com"]
    Client["浏览器"]

    UI --> Vol
    UI --> OpenAI
    UI --> Anthropic
    UI --> Google
    Client --> UI
```
**来源：** [README.md141-147](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L141-L147)

### 纯云端部署命令

```
docker run -d \
  -p 3000:8080 \
  -e OPENAI_API_KEY=your_secret_key \
  -v open-webui:/app/backend/data \
  --name open-webui \
  --restart always \
  ghcr.io/open-webui/open-webui:main
```
**关键配置：**

-   `-e OPENAI_API_KEY=your_secret_key` - OpenAI API 身份验证
-   不需要 `OLLAMA_BASE_URL`
-   CPU/内存需求极低
-   不需要 GPU

**来源：** [README.md143-147](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L143-L147)

### 其他 API 配置

除了 `OPENAI_API_KEY` 之外，Open WebUI 还支持多个 LLM 提供者：

| 提供者 | 环境变量 | 示例 |
| --- | --- | --- |
| **OpenAI** | `OPENAI_API_KEY` | `sk-...` |
| **Anthropic** | `ANTHROPIC_API_KEY` | `sk-ant-...` |
| **Google** | `GOOGLE_API_KEY` | `AIza...` |
| **自定义基准 URL** | `OPENAI_API_BASE_URL` | `https://api.groq.com/v1` |

通过设置各自的 API 密钥来同时配置多个提供者。

**来源：** [README.md32](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L32-L32) [README.md143-147](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L143-L147)

### 纯云端特点

| 方面 | 配置 |
| --- | --- |
| **镜像标签** | `ghcr.io/open-webui/open-webui:main` |
| **本地模型** | 无 - 仅使用外部 API |
| **需要 API 密钥** | 是 - 至少一个提供者 |
| **资源需求** | 极低 - 无需 GPU，CPU/内存占用低 |
| **成本模型** | 向 LLM 提供者按 API 调用次数付费 |
| **最佳适用** | 无本地 GPU、API 优先架构、最小化基础设施 |

**来源：** [README.md143-147](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L143-L147)

---

## 使用 Docker Compose 进行多容器编排

Docker Compose 通过明确的服务依赖和网络隔离支持多容器部署。集成测试工作流程展示了完整的多服务堆栈。

```mermaid
flowchart TD
    WebUI["open-webui 端口 3000:8080"]
    PG["postgres 端口 5432 健康检查: pg_isready"]
    OllamaService["ollama 端口 11434 卷: ollama-data"]
    RedisService["redis 端口 6379"]
    ChromaService["chromadb/chroma 端口 8000 持久化向量存储"]
    OWUIData["open-webui-data SQLite/上传/缓存"]
    OllamaData["ollama-data 模型"]
    ChromaData["chroma-data 嵌入"]
    PGData["postgres-data PostgreSQL 数据"]

    WebUI --> PG
    WebUI --> RedisService
    WebUI --> OllamaService
    WebUI --> ChromaService
    WebUI --> OWUIData
    OllamaService --> OllamaData
    ChromaService --> ChromaData
    PG --> PGData
```
### Docker Compose 架构

```mermaid
flowchart TD
    UI["ghcr.io/open-webui/open-webui:main 端口 3000:8080"]
    PG["postgres:16 端口 5432"]
    PGHealth["健康检查: pg_isready"]
    Redis["redis:7-alpine 端口 6379"]
    Ollama["ollama/ollama:latest 端口 11434"]
    Chroma["chromadb/chroma:latest 端口 8000"]
    UIVol["open-webui-data"]
    PGVol["postgres-data"]
    RedisVol["redis-data"]
    OllamaVol["ollama-data"]
    ChromaVol["chroma-data"]

    PG --> PGHealth
    UI --> PG
    UI --> Redis
    UI --> Ollama
    UI --> Chroma
    UI --> UIVol
    PG --> PGVol
    Redis --> RedisVol
    Ollama --> OllamaVol
    Chroma --> ChromaVol
```
**来源：** [.github/workflows/integration-test.disabled28-34](https://github.com/open-webui/open-webui/blob/a7271532/.github/workflows/integration-test.disabled#L28-L34) [.github/workflows/integration-test.disabled108-119](https://github.com/open-webui/open-webui/blob/a7271532/.github/workflows/integration-test.disabled#L108-L119)

### 生产环境 Docker Compose 示例

```yaml
services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    ports:
      - "3000:8080"
    volumes:
      - open-webui-data:/app/backend/data
    environment:
      - WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY}
      - DATABASE_URL=postgresql://user:pass@postgres:5432/openwebui
      - REDIS_URL=redis://redis:6379
      - OLLAMA_BASE_URL=http://ollama:11434
      - CHROMA_HTTP_HOST=chromadb
      - CHROMA_HTTP_PORT=8000
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started
    restart: always

  postgres:
    image: postgres:16
    environment:
      - POSTGRES_DB=openwebui
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: always

  redis:
    image: redis:7-alpine
    volumes:
      - redis-data:/data
    restart: always

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    restart: always

  chromadb:
    image: chromadb/chroma:latest
    ports:
      - "8000:8000"
    volumes:
      - chroma-data:/chroma/chroma
    restart: always

volumes:
  open-webui-data:
  postgres-data:
  redis-data:
  ollama-data:
  chroma-data:
```
### Docker Compose 服务发现

Compose 网络内的服务通过服务名称相互发现：

| 服务名称 | 解析 | 用途 |
| --- | --- | --- |
| `postgres` | `postgres:5432` | `DATABASE_URL=postgresql://user:pass@postgres:5432/db` |
| `redis` | `redis:6379` | `REDIS_URL=redis://redis:6379` |
| `ollama` | `ollama:11434` | `OLLAMA_BASE_URL=http://ollama:11434` |
| `chromadb` | `chromadb:8000` | `CHROMA_HTTP_HOST=chromadb`, `CHROMA_HTTP_PORT=8000` |

**来源：** [.github/workflows/integration-test.disabled28-34](https://github.com/open-webui/open-webui/blob/a7271532/.github/workflows/integration-test.disabled#L28-L34) [.github/workflows/integration-test.disabled108-119](https://github.com/open-webui/open-webui/blob/a7271532/.github/workflows/integration-test.disabled#L108-L119)

### 极简 Docker Compose (仅 UI + Ollama)

对于不需要外部数据库的简单部署：

```yaml
services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    ports:
      - "3000:8080"
    volumes:
      - open-webui-data:/app/backend/data
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      - ollama
    restart: always

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    restart: always

volumes:
  open-webui-data:
  ollama-data:
```
此配置使用 SQLite（默认）和本地文件存储，适用于开发或小规模部署。

**来源：** [.github/workflows/integration-test.disabled28-34](https://github.com/open-webui/open-webui/blob/a7271532/.github/workflows/integration-test.disabled#L28-L34)

---

## 容器环境变量配置

环境变量配置容器运行时的行为。有关环境变量的全面文档，请参阅第 3.3 页（环境配置）。

### 基本环境变量

| 变量 | 用途 | 默认值 | 示例 |
| --- | --- | --- | --- |
| `OLLAMA_BASE_URL` | Ollama API 端点 | `http://localhost:11434` | `http://ollama:11434` |
| `OPENAI_API_KEY` | OpenAI API 身份验证 | 无 | `sk-...` |
| `WEBUI_SECRET_KEY` | JWT 签名密钥 | 自动生成 | `openssl rand -hex 32` |
| `DATABASE_URL` | 数据库连接 | SQLite | `postgresql://user:pass@host:5432/db` |
| `REDIS_URL` | Redis 连接 | 无 (可选) | `redis://redis:6379/0` |

**来源：** [README.md129](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L129-L129) [README.md146](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L146-L146) [TROUBLESHOOTING.md32](https://github.com/open-webui/open-webui/blob/a7271532/TROUBLESHOOTING.md#L32-L32)

### LLM 提供者配置

| 变量 | 用途 | 默认值 |
| --- | --- | --- |
| `OLLAMA_BASE_URL` | 本地 Ollama 连接 | `http://localhost:11434` |
| `OPENAI_API_KEY` | OpenAI API 访问 | 无 |
| `OPENAI_API_BASE_URL` | 自定义兼容 OpenAI 的端点 | `https://api.openai.com/v1` |
| `ANTHROPIC_API_KEY` | Anthropic Claude 访问 | 无 |
| `GOOGLE_API_KEY` | Google Gemini 访问 | 无 |

**来源：** [README.md32](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L32-L32) [README.md143-147](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L143-L147) [TROUBLESHOOTING.md31-35](https://github.com/open-webui/open-webui/blob/a7271532/TROUBLESHOOTING.md#L31-L35)

---

## 卷管理

持久卷可以跨容器重启、更新和迁移保留数据。

### 容器文件系统结构

```mermaid
flowchart TD
    DataDir["/app/backend/data 主要卷"]
    OllamaDir["/root/.ollama Ollama 卷 (仅限捆绑镜像)"]
    DB["/app/backend/data/webui.db SQLite 数据库"]
    Uploads["/app/backend/data/uploads 用户文件"]
    Chroma["/app/backend/data/chroma.sqlite3 向量存储"]
    Cache["/app/backend/data/cache 模型缓存"]
    Models["/root/.ollama/models 下载的模型"]

    DataDir --> DB
    DataDir --> Uploads
    DataDir --> Chroma
    DataDir --> Cache
    OllamaDir --> Models
```
**来源：** [README.md114](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L114-L114) [README.md157-158](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L157-L158) [README.md164](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L164-L164) [backend/open_webui/storage/provider.py71-74](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/storage/provider.py#L71-L74)

### 命名卷 vs 绑定挂载

**命名卷 (推荐用于生产环境)：**

```
docker run -v open-webui:/app/backend/data ...
```
-   Docker 管理的存储
-   可在主机间移植
-   使用 `docker volume rm` 自动清理
-   在 macOS 和 Windows 上性能更好

**绑定挂载 (开发环境)：**

```
docker run -v ./local-data:/app/backend/data ...
```
-   直接访问主机文件系统
-   易于浏览和备份
-   对调试和开发很有用

**来源：** [README.md114](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L114-L114) [README.md124](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L124-L124)

### 关键卷挂载点

| 挂载点 | 用途 | 是否必需 | 部署类型 |
| --- | --- | --- | --- |
| `/app/backend/data` | 用户数据、SQLite、ChromaDB | 是 | 所有 |
| `/root/.ollama` | Ollama 模型 | 仅限 `:ollama` 标签 | 捆绑式 Ollama |

### 卷备份与迁移

**备份命名卷：**

```
docker run --rm -v open-webui:/data -v $(pwd):/backup \
  alpine tar czf /backup/open-webui-backup.tar.gz -C /data .
```
**恢复卷：**

```
docker run --rm -v open-webui:/data -v $(pwd):/backup \
  alpine sh -c "cd /data && tar xzf /backup/open-webui-backup.tar.gz"
```
**来源：** [README.md114](https://github.com/open-webui/open-webui/blob/a7271532/README.md#L114-L114)

---

## 存储后端配置

[backend/open_webui/storage/provider.py43-61](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/storage/provider.py#L43-L61) 中的 `StorageProvider` 抽象支持多种存储后端，通过 `STORAGE_PROVIDER` 环境变量选择。

### 存储提供者选择

`get_storage_provider` 函数根据配置实例化适当的提供者：

```mermaid
flowchart TD
    Config["STORAGE_PROVIDER 环境变量"]
    Factory["get_storage_provider()"]
    Local["LocalStorageProvider 文件系统存储"]
    S3["S3StorageProvider AWS S3 / 兼容"]
    GCS["GCSStorageProvider Google Cloud Storage"]
    Azure["AzureStorageProvider Azure Blob 存储"]
    Operations["upload_file() get_file() delete_file() delete_all_files()"]

    Config --> Factory
    Factory --> Local
    Factory --> S3
    Factory --> GCS
    Factory --> Azure
    Local --> Operations
    S3 --> Operations
    GCS --> Operations
    Azure --> Operations
```
**来源：** [backend/open_webui/storage/provider.py362-376](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/storage/provider.py#L362-L376)

### S3 存储提供者

`S3StorageProvider` 支持 AWS S3 和兼容 S3 的存储服务（MinIO、R2 等）。它实现了两种身份验证策略：

1.  **显式凭据**：使用 `S3_ACCESS_KEY_ID` 和 `S3_SECRET_ACCESS_KEY`
2.  **工作负载标识 (Workload Identity)**：使用 IAM 角色（EC2 实例配置文件、EKS 服务帐户等）

```
# 工作负载标识 (无需显式凭据)
if S3_ACCESS_KEY_ID and S3_SECRET_ACCESS_KEY:
    self.s3_client = boto3.client('s3', ...)
else:
    # 回退到默认的 AWS 凭据链
    self.s3_client = boto3.client('s3', ...)
```
提供者将文件上传到 S3，并带有可选的对象标记：

**来源：** [backend/open_webui/storage/provider.py108-224](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/storage/provider.py#L108-L224) [backend/open_webui/storage/provider.py120-138](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/storage/provider.py#L120-L138) [backend/open_webui/storage/provider.py148-177](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/storage/provider.py#L148-L177)

### GCS 存储提供者

`GCSStorageProvider` 支持 Google Cloud Storage，具有两种身份验证方法：

1.  **服务帐户 JSON**：使用 `GOOGLE_APPLICATION_CREDENTIALS_JSON`
2.  **元数据服务器**：使用默认应用凭据（GCE 实例、GKE 工作负载标识）

**来源：** [backend/open_webui/storage/provider.py226-290](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/storage/provider.py#L226-L290) [backend/open_webui/storage/provider.py230-239](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/storage/provider.py#S230-L239)

### Azure 存储提供者

`AzureStorageProvider` 支持 Azure Blob Storage，具有两种身份验证策略：

1.  **存储密钥**：使用 `AZURE_STORAGE_KEY`
2.  **托管标识 (Managed Identity)**：使用 `DefaultAzureCredential`（Azure VM、AKS 等）

**来源：** [backend/open_webui/storage/provider.py292-360](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/storage/provider.py#L292-L360) [backend/open_webui/storage/provider.py298-311](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/storage/provider.py#L298-L311)

---

## 容器中的数据库配置

Open WebUI 在容器化部署中同时支持 SQLite（默认）和 PostgreSQL。数据库类型由 `DATABASE_URL` 环境变量决定。

### SQLite 容器配置

默认情况下，使用 SQLite 且无需配置：

```
# SQLite (默认) - 无需 DATABASE_URL
docker run -v open-webui-data:/app/backend/data ...
```
数据库文件位置：`/app/backend/data/webui.db`

### PostgreSQL 容器配置

对于生产部署，推荐使用 PostgreSQL：

```
docker run \
  -e DATABASE_URL=postgresql://user:pass@postgres-host:5432/openwebui \
  -e DATABASE_POOL_SIZE=10 \
  -e DATABASE_POOL_MAX_OVERFLOW=10 \
  -e DATABASE_POOL_TIMEOUT=30 \
  ...
```
集成测试展示了 PostgreSQL 健康检查和连接韧性：

**来源：** [.github/workflows/integration-test.disabled181-209](https://github.com/open-webui/open-webui/blob/a7271532/.github/workflows/integration-test.disabled#L181-L209) [.github/workflows/integration-test.disabled211-228](https://github.com/open-webui/open-webui/blob/a7271532/.github/workflows/integration-test.disabled#L211-L228)

### 连接池配置

SQLAlchemy 连接池参数优化了容器化环境中的数据库连接管理：

| 参数 | 环境变量 | 用途 |
| --- | --- | --- |
| 连接池大小 | `DATABASE_POOL_SIZE` | 初始连接数 (默认: 10) |
| 最大溢出 | `DATABASE_POOL_MAX_OVERFLOW` | 超出连接池大小的额外连接数 |
| 池超时 | `DATABASE_POOL_TIMEOUT` | 等待可用连接的时间 (秒) |

**来源：** [.github/workflows/integration-test.disabled187-189](https://github.com/open-webui/open-webui/blob/a7271532/.github/workflows/integration-test.disabled#L187-L189)

---

## 容器中的 Redis 配置

Redis 是可选的，但在多实例部署中推荐使用。它提供分布式会话存储、缓存协调和实时事件协调。

### Redis 容器集成

```
docker run \
  -e REDIS_URL=redis://redis-host:6379/0 \
  ...
```
Redis 用于：

-   **会话存储**：用于分布式会话的 `starsessions[redis]` 后端
-   **WebSocket 状态**：用于会话池和使用情况跟踪的 `RedisDict`
-   **任务协调**：用于分布式任务管理的 Redis 发布/订阅 (Pub/Sub)
-   **配置缓存**：用于同步运行时配置的 `RedisConfig`

### Redis 连接字符串格式

```
redis://[:password@]host:port[/database]
```
示例：

-   `redis://redis:6379` - 无身份验证，默认数据库 (0)
-   `redis://:password@redis:6379/1` - 带密码，数据库 1
-   `rediss://redis:6379` - SSL/TLS 连接

**来源：** [backend/requirements.txt22](https://github.com/open-webui/open-webui/blob/a7271532/backend/requirements.txt#L22-L22) [backend/requirements.txt30](https://github.com/open-webui/open-webui/blob/a7271532/backend/requirements.txt#L30-L30)

---

## 网络配置

容器网络将 Open WebUI 连接到外部服务，并将 Web 界面暴露给客户端。

### 端口映射

容器内部暴露端口 `8080`，通常映射到不同的主机端口：

```
# 将容器端口 8080 映射到主机端口 3000
docker run -p 3000:8080 ...

# 映射到标准 HTTP 端口 80
docker run -p 80:8080 ...

# 绑定到特定接口
docker run -p 127.0.0.1:3000:8080 ...
```
### Docker Compose 中的服务发现

Docker Compose 创建一个默认网桥网络，服务通过服务名称相互发现：

```
services:
  open-webui:
    environment:
      - DATABASE_URL=postgresql://user:pass@postgres:5432/db
      - REDIS_URL=redis://redis:6379
      - OLLAMA_BASE_URL=http://ollama:11434
```
服务名称（`postgres`、`redis`、`ollama`）解析为 Compose 网络内的容器 IP 地址。

### 转发头 (Forwarded Headers)

 uvicorn 服务器配置了 `--forwarded-allow-ips '*'`，以便在部署在反向代理（nginx、Traefik 等）后面时信任代理头：

**来源：** [.github/workflows/integration-test.disabled162](https://github.com/open-webui/open-webui/blob/a7271532/.github/workflows/integration-test.disabled#L162-L162)

---

## 健康检查与就绪探针

健康检查确保服务在依赖服务启动之前已就绪，并使容器编排系统能够检测故障。

### Open WebUI 健康端点

应用程序暴露了健康检查端点：

-   `/health` - 常规应用程序健康状况
-   `/health/db` - 数据库连接性检查

### PostgreSQL 健康检查

集成测试展示了 PostgreSQL 健康检查：

```
postgres:
  healthcheck:
    test: ["CMD-SHELL", "pg_isready -U user"]
    interval: 10s
    timeout: 5s
    retries: 5
```
**来源：** [.github/workflows/integration-test.disabled113-117](https://github.com/open-webui/open-webui/blob/a7271532/.github/workflows/integration-test.disabled#L113-L117)

### 数据库重连韧性

系统能够优雅地处理数据库连接故障。集成测试验证了重连行为：

```
# 终止所有 PostgreSQL 连接
cur.execute('SELECT pg_terminate_backend(psa.pid) ...')

# 验证服务是否自动重连
status_code = curl('http://localhost:8081/health/db')
assert status_code == 200
```
**来源：** [.github/workflows/integration-test.disabled218-228](https://github.com/open-webui/open-webui/blob/a7271532/.github/workflows/integration-test.disabled#L218-L228)

### 服务启动协调

集成测试通过等待循环展示了服务启动协调：

```
# 等待服务变得可用
for i in {1..40}; do
    curl -s http://localhost:8080/api/config > /dev/null && break
    sleep 1
done
```
**来源：** [.github/workflows/integration-test.disabled165-173](https://github.com/open-webui/open-webui/blob/a7271532/.github/workflows/integration-test.disabled#L165-L173)

---

## 容器构建与测试

集成测试工作流程提供了关于容器构建和测试策略的见解。

### Docker Compose 构建

```
docker compose \
  --file docker-compose.yaml \
  --file docker-compose.api.yaml \
  --file docker-compose.a1111-test.yaml \
  up --detach --build
```
这展示了：

-   用于模块化服务定义的多文件 Compose 配置
-   构建时的镜像构造
-   CI/CD 管道的离线 (detached) 执行

**来源：** [.github/workflows/integration-test.disabled28-34](https://github.com/open-webui/open-webui/blob/a7271532/.github/workflows/integration-test.disabled#L28-L34)

### 构建缓存管理

为了在 CI 环境中回收磁盘空间：

```
docker builder prune --all --force
```
**来源：** [.github/workflows/integration-test.disabled36-38](https://github.com/open-webui/open-webui/blob/a7271532/.github/workflows/integration-test.disabled#L36-L38)

### 服务就绪验证

```
# 等待 Ollama 服务
until curl --output /dev/null --silent --fail http://localhost:11434; do
    printf '.'
    sleep 1
done
```
**来源：** [.github/workflows/integration-test.disabled40-47](https://github.com/open-webui/open-webui/blob/a7271532/.github/workflows/integration-test.disabled#L40-L47)

---

## 依赖与要求

容器包含了 requirements 文件中的所有 Python 依赖项。

### 核心依赖

| 类别 | 关键包 | 用途 |
| --- | --- | --- |
| Web 框架 | `fastapi==0.123.0`, `uvicorn[standard]==0.37.0` | ASGI 应用程序服务器 |
| 数据库 | `sqlalchemy==2.0.38`, `alembic==1.17.2` | ORM 和迁移 |
| 会话 | `starsessions[redis]==2.2.1` | 分布式会话管理 |
| 实时 | `python-socketio==5.15.0`, `redis` | WebSocket 和状态协调 |
| 身份验证 | `PyJWT[crypto]==2.10.1`, `authlib==1.6.5`, `bcrypt==5.0.0` | 认证机制 |
| 存储 | `boto3==1.41.5`, `google-cloud-storage==2.19.0`, `azure-storage-blob==12.24.1` | 云存储客户端 |
| 向量数据库 | `chromadb==1.1.0`, `weaviate-client==4.17.0`, `pymilvus==2.6.4` | 嵌入存储 |

**来源：** [backend/requirements.txt1-153](https://github.com/open-webui/open-webui/blob/a7271532/backend/requirements.txt#L1-L153) [pyproject.toml8-117](https://github.com/open-webui/open-webui/blob/a7271532/pyproject.toml#L8-L117)

### 最小依赖

`requirements-min.txt` 为轻量级容器定义了最小依赖集：

```
fastapi==0.123.0
uvicorn[standard]==0.37.0
pydantic==2.12.5
python-socketio==5.15.0
...
```
此最小集排除了以下可选功能：

-   高级文档加载器 (Tika, Marker, Docling)
-   多个向量数据库客户端
-   云存储 SDK
-   OCR 和文档智能服务

**来源：** [backend/requirements-min.txt1-52](https://github.com/open-webui/open-webui/blob/a7271532/backend/requirements-min.txt#L1-L52)

### 可选依赖

`pyproject.toml` 定义了可选依赖组：

```
[project.optional-dependencies]
postgres = [
    "psycopg2-binary==2.9.10",
    "pgvector==0.4.1",
]

all = [
    "pymongo",
    "psycopg2-binary==2.9.9",
    "qdrant-client==1.14.3",
    "weaviate-client==4.17.0",
    ...
]
```
**来源：** [pyproject.toml131-158](https://github.com/open-webui/open-webui/blob/a7271532/pyproject.toml#L131-L158)

---

## 在容器中测试存储提供者

测试套件演示了如何在容器化环境中验证存储提供者的功能。

### 存储提供者测试设置

测试使用模拟 (mocking) 和仿真来验证存储提供者，而不需要实际的云服务：

```python
@mock_aws  # 使用 moto 模拟 AWS 服务
class TestS3StorageProvider:
    def test_upload_file(self):
        self.s3_client.create_bucket(Bucket=bucket_name)
        contents, s3_file_path = Storage.upload_file(...)
```
### GCS 仿真器测试

对于 GCS，测试使用 `gcp-storage-emulator`：

```python
server = create_server("localhost", 9023, in_memory=True)
server.start()
os.environ["STORAGE_EMULATOR_HOST"] = f"http://localhost:9023"
```
### Azure 存储测试

Azure 测试使用 `MagicMock` 来模拟 Blob 存储 API，而不需要实际的 Azure 资源：

```python
mock_blob_service_client = MagicMock()
mock_container_client = MagicMock()
```
**来源：** [backend/open_webui/test/apps/webui/storage/test_provider.py100-189](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/test/apps/webui/storage/test_provider.py#L100-L189) [backend/open_webui/test/apps/webui/storage/test_provider.py202-292](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/test/apps/webui/storage/test_provider.py#L202-L292) [backend/open_webui/test/apps/webui/storage/test_provider.py294-436](https://github.com/open-webui/open-webui/blob/a7271532/backend/open_webui/test/apps/webui/storage/test_provider.py#L294-L436)
